{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import plotly.express as px \n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "\n",
    "We just saw how cross-validation can help find a dimension for a fitted model that balances under- and overfitting. Rather than selecting the dimension of the model, we can build a model with all of the features, but restrict the size of the coefficients. We keep from overfitting by adding to the MSE a penalty term on the size of the coefficients. The penalty, called a *regularization term*, is $ \\alpha$.   We fit the model by minimizing the combination of mean squared error plus this penalty:\n",
    "\n",
    "\n",
    "When the *regularization parameter*, $\\alpha$, is large, it penalizes large coefficients.\n",
    "(We typically choose it by cross-validation.) \n",
    "\n",
    "A popular regularization is called *lasso regression* (lasso stands for Least Absolute Shrinkage and Selection Operator). It penalizes the absolute size of the coefficients: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\mathbf{x}_i \\boldsymbol{\\theta})^2  ~+~ \\alpha \\sum_{j = 1}^{p} |\\theta_j|\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    " \n",
    "To get an idea about how regularization works, let's think about the extreme cases: when $ \\alpha $ is really large and when it's close to 0 ($ \\alpha $ is never negative). With a big regularization parameter, the coefficients are heavily penalized, so they shrink. On the other hand, when $ \\alpha $ is tiny, the coefficients aren't restricted. In fact, when $ \\alpha $ is 0, we're back in the world of ordinary least squares. A couple of issues crop up when we think about controlling the size of the coefficients through regularization: \n",
    " \n",
    "+ We do not want to regularize the intercept term. This way, a large penalty fits a constant model.\n",
    "+ When features have very different scales, the penalty can impact them differently, with large-valued features being penalized more than others. To avoid this, we standardize all of the features to have mean 0 and variance 1 before fitting the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using regularization allows us to avoid model overfitting by penalizing large coefficients.  $ L_1 $ regularization has the advantage of zeroing out coefficients; it performs *feature selection* by discarding the features with a coefficient of 0. This is particularly useful when working with high-dimensional data with many features. A model that only uses a few features to make a prediction runs much faster than a model that requires many calculations. Since unneeded features tend to increase model variance without decreasing bias, we can sometimes increase the accuracy of other models by using lasso regression to select a subset of features to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example with 35 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: A Market Analysis\n",
    "\n",
    "A [market research project](https://doi.org/10.1080/02664763.2014.994480) for a pharmaceutical company wants to model consumer interest in purchasing a cold sore health-care product. They gather data from 1,023 consumers. Each consumer is asked to rate on a 10-point scale 35 factors according to whether the factor matters to them when considering purchasing a cold sore treatment. They also rate their interest in purchasing the product. \n",
    "\n",
    "Stan Lipovetsky and W. Michael Conklin (2015) Predictor relative importance\n",
    "and matching regression parameters. _Journal of Applied Statistics_, 42:5, 1017-1031."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by reading in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_df = pd.read_csv('data/market-analysis.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below lists the 35 factors and provides their correlation to the outcome, their interest in purchasing the product. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "|  | Corr | Description |  | Corr | Description |\n",
    "| --- | --- | --------- | --- | --- | --------- |\n",
    "| x1  | 0.70 | provides soothing relief | x19 | 0.54 | has a non-messy application |\n",
    "| x2  | 0.58 | moisturizes cold sore blister | x20 | 0.70 | good for any stage of a cold |\n",
    "| x3  | 0.69 | provides long-lasting relief | x21 | 0.49 | easy to apply/take |\n",
    "| x4  | 0.70 | provides fast-acting relief | x22 | 0.52 | package keeps from contamination |\n",
    "| x5 | 0.72 | shortens duration of a cold | x23 | 0.57 | easy to dispense a right amount |\n",
    "| x6  | 0.68 | stops the virus from spreading | x24 | 0.63 | worth the price it costs |\n",
    "| x7 | 0.67| dries up cold sore | x25 | 0.57 | recommended most by pharamacists |\n",
    "| x8 | 0.72 | heals fast | x26 | 0.54 | recommended by doctors |\n",
    "| x9 | 0.72 | penetrates deep | x27 | 0.54 | FDA approved |\n",
    "| x10 | 0.65 | relieves pain | x28 | 0.64 | a brand I trust |\n",
    "| x11 |0.61 | prevents cold | x29 | 0.60 | clinically proven |\n",
    "| x12 | 0.73 | prevents from getting worse | x30 | 0.68 | a brand I would recommend |\n",
    "| x13 | 0.57 | medicated | x31 | 0.74 | an effective treatment |\n",
    "| x14 | 0.61 | prescription strength | x32  |0.37 | portable |\n",
    "| x15 | 0.63 | repairs damaged skin | x33 | 0.37 | discreet packaging |\n",
    "| x16 | 0.67 | blocks virus from spreading | x34 | 0.55 | helps conceal cold sores |\n",
    "| x17 | 0.42 | contains SPF | x35 | 0.63 | absorbs quickly |\n",
    "| x18 | 0.57 | non-irritating | | | |\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ma_df[\"y\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on their labels alone, some of these 35 features appear to measure similar aspects of desirability. We can compute the correlations between the explanatory variables to confirm this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>x33</th>\n",
       "      <th>x34</th>\n",
       "      <th>x35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.584470</td>\n",
       "      <td>0.689198</td>\n",
       "      <td>0.698104</td>\n",
       "      <td>0.715737</td>\n",
       "      <td>0.675171</td>\n",
       "      <td>0.674324</td>\n",
       "      <td>0.720245</td>\n",
       "      <td>0.715239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543472</td>\n",
       "      <td>0.535300</td>\n",
       "      <td>0.643565</td>\n",
       "      <td>0.599936</td>\n",
       "      <td>0.681561</td>\n",
       "      <td>0.744036</td>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.365545</td>\n",
       "      <td>0.553436</td>\n",
       "      <td>0.627739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.698082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>0.741297</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.733237</td>\n",
       "      <td>0.715636</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.781493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545061</td>\n",
       "      <td>0.555448</td>\n",
       "      <td>0.669401</td>\n",
       "      <td>0.632966</td>\n",
       "      <td>0.675034</td>\n",
       "      <td>0.786363</td>\n",
       "      <td>0.420447</td>\n",
       "      <td>0.327813</td>\n",
       "      <td>0.573375</td>\n",
       "      <td>0.714993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.584470</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632579</td>\n",
       "      <td>0.652231</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.626027</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.628247</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520121</td>\n",
       "      <td>0.535033</td>\n",
       "      <td>0.608308</td>\n",
       "      <td>0.600972</td>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.658305</td>\n",
       "      <td>0.426040</td>\n",
       "      <td>0.355965</td>\n",
       "      <td>0.546330</td>\n",
       "      <td>0.631601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.689198</td>\n",
       "      <td>0.741297</td>\n",
       "      <td>0.632579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775006</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.781304</td>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>0.766581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559115</td>\n",
       "      <td>0.571977</td>\n",
       "      <td>0.634122</td>\n",
       "      <td>0.665531</td>\n",
       "      <td>0.635772</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>0.366715</td>\n",
       "      <td>0.343737</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.697526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.698104</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>0.652231</td>\n",
       "      <td>0.775006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791758</td>\n",
       "      <td>0.763113</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>0.782780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.649257</td>\n",
       "      <td>0.628049</td>\n",
       "      <td>0.674396</td>\n",
       "      <td>0.816444</td>\n",
       "      <td>0.386155</td>\n",
       "      <td>0.316505</td>\n",
       "      <td>0.595784</td>\n",
       "      <td>0.715873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           y        x1        x2        x3        x4        x5        x6  \\\n",
       "y   1.000000  0.698082  0.584470  0.689198  0.698104  0.715737  0.675171   \n",
       "x1  0.698082  1.000000  0.693949  0.741297  0.806206  0.745964  0.733237   \n",
       "x2  0.584470  0.693949  1.000000  0.632579  0.652231  0.629310  0.626027   \n",
       "x3  0.689198  0.741297  0.632579  1.000000  0.775006  0.764568  0.781304   \n",
       "x4  0.698104  0.806206  0.652231  0.775006  1.000000  0.791758  0.763113   \n",
       "\n",
       "          x7        x8        x9  ...       x26       x27       x28       x29  \\\n",
       "y   0.674324  0.720245  0.715239  ...  0.543472  0.535300  0.643565  0.599936   \n",
       "x1  0.715636  0.764331  0.781493  ...  0.545061  0.555448  0.669401  0.632966   \n",
       "x2  0.606470  0.628247  0.667748  ...  0.520121  0.535033  0.608308  0.600972   \n",
       "x3  0.716138  0.795831  0.766581  ...  0.559115  0.571977  0.634122  0.665531   \n",
       "x4  0.742654  0.812947  0.782780  ...  0.566515  0.550485  0.649257  0.628049   \n",
       "\n",
       "         x30       x31       x32       x33       x34       x35  \n",
       "y   0.681561  0.744036  0.370732  0.365545  0.553436  0.627739  \n",
       "x1  0.675034  0.786363  0.420447  0.327813  0.573375  0.714993  \n",
       "x2  0.618307  0.658305  0.426040  0.355965  0.546330  0.631601  \n",
       "x3  0.635772  0.795528  0.366715  0.343737  0.667460  0.697526  \n",
       "x4  0.674396  0.816444  0.386155  0.316505  0.595784  0.715873  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_df.corr().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, for example, that the last feature, \"absorbs quickly,\" is highly correlated with the first three: \"provides soothing relief,\" \"moisturizes,\" and \"provides long-lasting relief.\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Training, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to fit regularized models, we set up the design matrix and outcome vector and split the data into trainining, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ma_df[\"y\"]\n",
    "X = ma_df.drop(columns=[\"y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of full dataset: 1023 points\n",
      "Size of training set: 818 points\n",
      "Size of test set: 205 points\n",
      "Size of original training set: 818 points\n",
      "Size of mini training set: 654 points\n",
      "Size of validation set: 164 points\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=100, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "print(f\"Size of full dataset: {X.shape[0]} points\")\n",
    "print(f\"Size of training set: {X_train.shape[0]} points\")\n",
    "print(f\"Size of test set: {X_test.shape[0]} points\")\n",
    "\n",
    "\n",
    "# Split X_train further into X_train_mini and X_val.\n",
    "X_train_mini, X_val, Y_train_mini, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=18)\n",
    "\n",
    "print(f\"Size of original training set: {X_train.shape[0]} points\")\n",
    "print(f\"Size of mini training set: {X_train_mini.shape[0]} points\")\n",
    "print(f\"Size of validation set: {X_val.shape[0]} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Fit your linear model\n",
    "\n",
    "linear_model.fit(X_train_mini, Y_train_mini);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE:\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    return np.sqrt(np.mean((y - yhat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.030785771794295"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Training RMSE:\n",
    "\n",
    "Y_train_predict = linear_model.predict(X_train_mini)\n",
    "\n",
    "rmse(Y_train_predict, Y_train_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696294251843102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Validation RMSE:\n",
    "\n",
    "Y_val_predict = linear_model.predict(X_val)\n",
    "\n",
    "rmse(Y_val, Y_val_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense as to whether our training RMSE was a result of the random sample of size 20% that we used for the validation set, we can use 5-fold Cross Validation on the entire training set and take the average of the RMSE values for the 5-folds.  This will likely be a closer representation of the actual test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross validation RMSE.  \n",
    "# Python is set-up to create the folds for you, so we use the entire X-train and Y-train set:\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def cross_validate_rmse(model, X_train, Y_train):\n",
    "    model = clone(model)\n",
    "    five_fold = KFold(n_splits=5)\n",
    "    rmse_values = []\n",
    "    for tr_ind, va_ind in five_fold.split(X_train):\n",
    "        model.fit(X_train.iloc[tr_ind,:], Y_train.iloc[tr_ind])\n",
    "        rmse_values.append(rmse(Y_train.iloc[va_ind], model.predict(X_train.iloc[va_ind,:])))\n",
    "    return np.mean(rmse_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0942880728677857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_rmse(linear_model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Before fitting a regularized model we need to standardize the features. \n",
    "\n",
    "First, we'll standardize the mini-train set, and then, when we go to evaluate the model, we use the mini-train set standardization on the validation-set. The [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) method helps us with this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX = StandardScaler().fit(X_train_mini) \n",
    "X_train_scaled = scalerX.transform(X_train_mini)\n",
    "X_val_scaled = scalerX.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that the means of the 35 features in the train set are all 0 and the SDs are all&nbsp;1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(X_train_scaled.mean(axis=0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(X_train_scaled.std(axis=0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that this is not the case for the test set, because we\n",
    "use the averages and SDs from the train set to standardize the test set features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a lasso regression, we use the `Lasso` method in `scikit-learn`.  Let's see how the coefficients for the 35 features in the data frame change with $\\alpha$. We set up a range of values for the regularization parameter and fit the lasso for each (this parameter is referred to as `alpha` in `Lasso`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "coefs = []\n",
    "rmses = []\n",
    "alphas = np.arange(0.01, 1.5, 0.01)\n",
    "\n",
    "for a in alphas:\n",
    "    model = Lasso(alpha=a)\n",
    "    model.fit(X_train_scaled, Y_train_mini)\n",
    "    coefs.append(model.coef_)\n",
    "    rmses.append(rmse(Y_val, model.predict(X_val_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature, we can overlay a line plot of the coefficient against $ \\alpha $: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "col_names = [\"x\" + str(v) for v in np.arange(1, 36, 1)]\n",
    "\n",
    "coefs_df = pd.DataFrame(coefs, columns=col_names)\n",
    "\n",
    "coefs_df[\"alpha\"] = alphas\n",
    "coefs_long = pd.melt(coefs_df, id_vars=[\"alpha\"], value_vars=col_names)\n",
    "\n",
    "fig = px.line(coefs_long, x=\"alpha\", y=\"value\", color=\"variable\", log_x=False)\n",
    "fig.update_layout(\n",
    "    showlegend=False, width=550, height=250, yaxis_title=\"Coefficient\",\n",
    "    xaxis_title=\"alpha\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $ \\alpha $ increases, the model fitting is penalized more heavily and many coefficients shrink to 0. The lefthand side of the plot shows greater model complexity and corresponds to small $ \\alpha $. Notice that for $ \\lambda = 0.5 $, nearly all of the coefficients are 0. \n",
    "\n",
    "We can also plot the RMSE as a function of $ \\alpha $ to see how it changes with the increase in the penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=alphas, y=rmses,\n",
    "        labels={\"x\": \"alpha\", \"y\": \"RMSE\"},\n",
    "        width=350, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $ \\alpha $ reaches about 1.35, the penalty is so large that the lasso regression is simply fitting a constant model to the data, and the MSE doesn't change. We are again faced with a model selection question, but this time it's in the form of deciding on $ \\alpha $. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing alpha:  \n",
    "\n",
    "If you're interested in creating a simple model with just a select number of important predictors you can choose the alpha that results in your chosen number of predictors.  For example, suppose we want a model with just 6 predictors.    We can see in the alpha vs coefficient plot above, that an alpha value around .80 will result in a model with 6 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Lasso(alpha=.80)\n",
    "\n",
    "model_2.fit(X_train_scaled, Y_train_mini)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(Y_val, model.predict(X_val_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cross-Validation to Choose alpha:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead your goal is to find the \"best\" alpha that minimizes RMSE, we can use cross-validation to help us. \n",
    "\n",
    "We use the `LassoCV` method to perform 5-fold cross-validation to choose $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv_model = LassoCV(\n",
    "    alphas=np.arange(0.01, 1, 0.01), cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the full (not the mini) training set (since Python knows we're using cross validation to help us with model selection (i.e. to help us choose alpha).  \n",
    "So first we need to re-standardize using the full training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX_full = StandardScaler().fit(X_train) \n",
    "X_train_full_scaled = scalerX_full.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best = lasso_cv_model.fit(X_train_full_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation has chosen the following regularization parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_best.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find how many coefficients (out of the original 35) are not 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.abs(lasso_best.coef_) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Version of Model:  Lasso Regression with alpha = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running on the test set, we need to standardize the test data.\n",
    "# We'll use the standardization we used on the full training set.\n",
    "\n",
    "X_test_scaled = scalerX_full.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0989705839439465"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE from test set (only run this once at end!)\n",
    "Y_test_pred = lasso_best.predict(X_test_scaled)\n",
    "rmse(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T TRY THIS AT HOME!\n",
    "# We'll peek under the hood and see if this actually performs better on the test set than\n",
    "# the OLS model using all the parameters.  \n",
    "\n",
    "Y_test_pred_orig = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1535784835058613"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(Y_test, Y_test_pred_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yep!  Our regularized model is better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Sometimes we prefer one type of regularization over the other because it maps more closely to the domain we are working with. For example, if we know that the phenomenon we are trying to model results from many small factors, we might prefer ridge regression because it won't discard these factors. On the other hand, some outcomes result from a few highly influential features. We prefer lasso regression in these situations because it discards unneeded features. Both $L_2$ and $L_1$ serve as useful throttles to navigate between under- and overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization, train-test split, and cross-validation all have the goal of reducing over-fitting. The problem with over-fitting comes from using data to both fit a model and estimate the model's error in predicting new observations. In the next section, we provide further intuition for this idea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
