{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374b42b7-3087-4b6a-95b3-315feb64767b",
   "metadata": {},
   "source": [
    "# Lecture 29: Cross Validation\n",
    "\n",
    "\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/fa23/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e7fd03-0858-406d-9d56-c831e63bcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5b20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d17a42-8459-40df-a9b3-d8c8d48bc641",
   "metadata": {},
   "source": [
    "In this lecture, we will work with the `vehicles` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d390cfe-927b-43d9-982b-93e149f2d31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>20.5</td>\n",
       "      <td>70</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen 1131 deluxe sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>21.0</td>\n",
       "      <td>73</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen super beetle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>43.4</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2335</td>\n",
       "      <td>23.7</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw dasher (diesel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>44.3</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2085</td>\n",
       "      <td>21.7</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw rabbit c (diesel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>43.1</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>21.5</td>\n",
       "      <td>78</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen rabbit custom diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement    hp  weight  acceleration  model_year  \\\n",
       "19   26.0          4          97.0  46.0    1835          20.5          70   \n",
       "102  26.0          4          97.0  46.0    1950          21.0          73   \n",
       "326  43.4          4          90.0  48.0    2335          23.7          80   \n",
       "325  44.3          4          90.0  48.0    2085          21.7          80   \n",
       "244  43.1          4          90.0  48.0    1985          21.5          78   \n",
       "\n",
       "     origin                             name  \n",
       "19   europe     volkswagen 1131 deluxe sedan  \n",
       "102  europe          volkswagen super beetle  \n",
       "326  europe               vw dasher (diesel)  \n",
       "325  europe             vw rabbit c (diesel)  \n",
       "244  europe  volkswagen rabbit custom diesel  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles = sns.load_dataset(\"mpg\").rename(columns={\"horsepower\":\"hp\"}).dropna().sort_values(\"hp\")\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f06f1",
   "metadata": {},
   "source": [
    "# I) Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27378d6-516e-417a-b80a-0282ea4243df",
   "metadata": {},
   "source": [
    "Suppose we want to use the `hp` (horsepower) of a car to predict its `mpg` (gas mileage in miles per gallon). If we visualize the relationship between these two variables, we see a non-linear curvature. Fitting a linear model to these variables results in a high (poor) value of RMSE. \n",
    "\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 (\\text{hp})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33629843-f23d-4624-accf-a9b6af482d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = vehicles[[\"hp\"]]\n",
    "y = vehicles[\"mpg\"]\n",
    "\n",
    "\n",
    "hp_model = lm.LinearRegression()\n",
    "hp_model.fit(X, y)\n",
    "hp_model_predictions = hp_model.predict(X)\n",
    "\n",
    "sns.scatterplot(data=vehicles, x=\"hp\", y=\"mpg\")\n",
    "\n",
    "plt.plot(vehicles[\"hp\"], hp_model_predictions, c=\"tab:red\");\n",
    "\n",
    "print(f\"RMSE of model with (hp) feature: {np.sqrt(np.mean((y-hp_model_predictions)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249691a7-ea35-493c-ad04-f224e61f50c4",
   "metadata": {},
   "source": [
    "To capture the non-linear relationship between the variables, we can introduce a non-linear feature: `hp` squared. Our new model is:\n",
    "\n",
    "$$\\hat{y} = \\theta_0 + \\theta_1 (\\text{hp}) + \\theta_2 (\\text{hp}^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f79d3-df91-408e-b78d-3ba61a7a6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vehicles[[\"hp\"]]\n",
    "X.loc[:, \"hp^2\"] = vehicles[\"hp\"]**2\n",
    "\n",
    "hp2_model = lm.LinearRegression()\n",
    "hp2_model.fit(X, y)\n",
    "hp2_model_predictions = hp2_model.predict(X)\n",
    "\n",
    "sns.scatterplot(data=vehicles, x=\"hp\", y=\"mpg\")\n",
    "\n",
    "plt.plot(vehicles[\"hp\"], hp2_model_predictions, c=\"tab:red\");\n",
    "\n",
    "print(f\"RMSE of model with (hp^2) feature: {np.sqrt(np.mean((y-hp2_model_predictions)**2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6337bad5-873a-48ca-aa70-ba2467b60619",
   "metadata": {},
   "source": [
    "What if we take things further and add even *more* polynomial features?\n",
    "\n",
    "\n",
    "For example, a degree 4 polynomial based on the `hp` feature to predict `mpg` can be characterized as follows:\n",
    "\n",
    "$$\\widehat{mpg} = \\theta_0 + \\theta_1 hp + \\theta_2 hp^2 + \\theta_3 hp^3 + \\theta_4 hp^4$$\n",
    "\n",
    "The cell below fits models of increasing complexity and computes their MSEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8032da0c-757a-4472-940c-e72718bc514c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp^4\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vehicles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Fit a model with order 3\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m hp3_model \u001b[38;5;241m=\u001b[39m \u001b[43mlm\u001b[49m\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m     12\u001b[0m hp3_model\u001b[38;5;241m.\u001b[39mfit(X[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp^2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp^3\u001b[39m\u001b[38;5;124m\"\u001b[39m]], vehicles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m hp3_model_predictions \u001b[38;5;241m=\u001b[39m hp3_model\u001b[38;5;241m.\u001b[39mpredict(X[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp^2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhp^3\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "def mse(predictions, observations):\n",
    "    return np.mean((observations - predictions)**2)\n",
    "\n",
    "\n",
    "\n",
    "# Add hp^3 and hp^4 as features to the data\n",
    "X[\"hp^3\"] = vehicles[\"hp\"]**3\n",
    "X[\"hp^4\"] = vehicles[\"hp\"]**4\n",
    "\n",
    "# Fit a model with order 3\n",
    "hp3_model = lm.LinearRegression()\n",
    "hp3_model.fit(X[[\"hp\", \"hp^2\", \"hp^3\"]], vehicles[\"mpg\"])\n",
    "hp3_model_predictions = hp3_model.predict(X[[\"hp\", \"hp^2\", \"hp^3\"]])\n",
    "\n",
    "# Fit a model with order 4\n",
    "hp4_model = lm.LinearRegression()\n",
    "hp4_model.fit(X[[\"hp\", \"hp^2\", \"hp^3\", \"hp^4\"]], vehicles[\"mpg\"])\n",
    "hp4_model_predictions = hp4_model.predict(X[[\"hp\", \"hp^2\", \"hp^3\", \"hp^4\"]])\n",
    "\n",
    "# Plot the models' predictions\n",
    "fig, ax = plt.subplots(1, 3, dpi=200, figsize=(12, 3))\n",
    "\n",
    "predictions_dict = {0:hp2_model_predictions, 1:hp3_model_predictions, 2:hp4_model_predictions}\n",
    "\n",
    "for i in predictions_dict:\n",
    "    ax[i].scatter(vehicles[\"hp\"], vehicles[\"mpg\"], edgecolor=\"white\", lw=0.5)\n",
    "    ax[i].plot(vehicles[\"hp\"], predictions_dict[i], \"tab:red\")\n",
    "    ax[i].set_title(f\"Model with order {i+2}\")\n",
    "    ax[i].set_xlabel(\"hp\")\n",
    "    ax[i].set_ylabel(\"mpg\")\n",
    "    ax[i].annotate(f\"Training RMSE: {np.round(np.sqrt(mse(vehicles['mpg'], predictions_dict[i])), 3)}\", (120, 40))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266b33f-37c6-4d39-b19c-f18fc576b19a",
   "metadata": {},
   "source": [
    "## Complexity and Overfitting\n",
    "\n",
    "What we saw above was the phenomenon of **model complexity** – as we add additional features to the design matrix, the model becomes increasingly *complex*. Models with higher complexity have lower values of training error. Intuitively, this makes sense: with more features at its disposal, the model can match the observations in the trainining data more and more closely. \n",
    "\n",
    "We can run an experiment to see this in action. In the cell below, we fit many models of progressively higher complexity, then plot the MSE of predictions on the training set. The code used (specifically, the `Pipeline` and `PolynomialFeatures` functions of `sklearn`) is just for efficiency - this code is out of scope of CSCI 3022.\n",
    "\n",
    "The **order** of a polynomial model is the highest power of any term in the model. An order 0 model takes the form $\\hat{y} = \\theta_0$, while an order 4 model takes the form $\\hat{y} = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c06c3-f3bb-452f-acef-6df2661affbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def fit_model_dataset(degree, dataset):\n",
    "    pipelined_model = Pipeline([\n",
    "            ('polynomial_transformation', PolynomialFeatures(degree)),\n",
    "            ('linear_regression', lm.LinearRegression())    \n",
    "        ])\n",
    "\n",
    "    pipelined_model.fit(dataset[[\"hp\"]], dataset[\"mpg\"])\n",
    "    return np.sqrt(mse(dataset['mpg'], pipelined_model.predict(dataset[[\"hp\"]])))\n",
    "\n",
    "errors = [fit_model_dataset(degree, vehicles) for degree in range(0, 10)]\n",
    "RMSEs_and_k = pd.DataFrame({\"k\": range(0, 10), \"RMSE\": errors})\n",
    "\n",
    "plt.plot(range(0, 10), errors)\n",
    "plt.xlabel(\"Model Complexity (degree of polynomial)\")\n",
    "plt.ylabel(\"Training RMSE\");\n",
    "\n",
    "def plot_degree_k_model(k, RMSEs_and_k, axs):\n",
    "    pipelined_model = Pipeline([\n",
    "        ('poly_transform', PolynomialFeatures(degree = k)),\n",
    "        ('regression', lm.LinearRegression(fit_intercept = True))    \n",
    "    ])\n",
    "    pipelined_model.fit(vehicles[[\"hp\"]], vehicles[\"mpg\"])\n",
    "    \n",
    "    row = k // 5\n",
    "    col = k % 5\n",
    "    ax = axs[row, col]\n",
    "    \n",
    "    sns.scatterplot(data=vehicles, x='hp', y='mpg', ax=ax)\n",
    "    \n",
    "    x_range = np.linspace(45, 210, 100).reshape(-1, 1)\n",
    "    ax.plot(x_range, pipelined_model.predict(pd.DataFrame(x_range, columns=['hp'])), c='tab:red', linewidth=2)\n",
    "    \n",
    "    ax.set_ylim((0, 50))\n",
    "    mse_str = f\"RMSE: {RMSEs_and_k.loc[k, 'RMSE']:.4}\\nDegree: {k}\"\n",
    "    ax.text(130, 35, mse_str, dict(size=14))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6), dpi=150)\n",
    "axs = fig.subplots(nrows=2, ncols=5)\n",
    "\n",
    "for k in range(10):\n",
    "    plot_degree_k_model(k, RMSEs_and_k, axs)\n",
    "fig.subplots_adjust(wspace=0.4, hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197e1e3-681c-4192-8cd1-b7c97c936cbe",
   "metadata": {},
   "source": [
    "As the model increases in polynomial degree (that is, it increases in complexity), the training RMSE decreases, plateauing at roughly ~4.3.\n",
    "\n",
    "In fact, it is a mathematical fact that if we create a polynomial model with degree $n-1$, we can *perfectly* model a set of $n$ points (assuming all $n$ points describe a function). For example, a set of 5 points can be perfectly modeled by a degree 4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb0a9a-7052-4dcc-83a3-3b72546688fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, dpi=200, figsize=(12, 3))\n",
    "\n",
    "for i in range(0, 3):\n",
    "    points = 3*np.random.uniform(size=(5, 2))\n",
    "\n",
    "    polynomial_model = Pipeline([\n",
    "                ('polynomial_transformation', PolynomialFeatures(4)),\n",
    "                ('linear_regression', lm.LinearRegression())    \n",
    "            ])\n",
    "\n",
    "    polynomial_model.fit(points[:, [0]], points[:, 1])\n",
    "\n",
    "    ax[i].scatter(points[:, 0], points[:, 1])\n",
    "\n",
    "    xs = np.linspace(0, 3)\n",
    "    ax[i].plot(xs, polynomial_model.predict(xs[:, np.newaxis]), c=\"tab:red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91667111-8fef-4fed-9c23-6f204796737a",
   "metadata": {},
   "source": [
    "You may be tempted to always design models with high polynomial degree – after all, we know that we could theoretically achieve perfect predictions by creating a model with enough polynomial features. \n",
    "\n",
    "It turns out that the examples we looked at above represent a somewhat artificial scenario: we trained our model on all the data we had available, then used the model to make predictions on this very same dataset. A more realistic situation is when we wish to apply our model on unseen data – that is, datapoints that it did not encounter during the model fitting process. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407655a",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5091d0",
   "metadata": {},
   "source": [
    "## Train-Test-Validation Split\n",
    "\n",
    "The first thing we will want to do with this data is construct a train/test/validation split. Constructing a train/test/validation test split before EDA and data cleaning can often be helpful.  This allows us to see if our data cleaning and any conclusions we draw from visualizations generalize to new data. This can be done by re-running the data cleaning and EDA process on the test dataset.\n",
    "\n",
    "Let's set aside 20% of our data for testing, and then further split the remaining 80% into 80% and 20% for training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame `data` and randomly splits it into three smaller DataFrames \n",
    "    named 'test', `train` and `validation` with 20% and 64% and 16% of the data, respectively. \n",
    "    \"\"\"\n",
    "\n",
    "    data_len = data.shape[0]\n",
    "\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    \n",
    "    \n",
    "    # Set train equal to the first 64%  of shuffled_indices\n",
    "    train_indices = shuffled_indices[:int(data_len * 0.64)]\n",
    "    # Set valid equal to the next 16% of shuffled_indices\n",
    "    validation_indices = shuffled_indices[int(data_len * 0.64):int(data_len*.80)]\n",
    "    # Set test equal to the last 20% of shuffled_indices\n",
    "    test_indices = shuffled_indices[int(data_len * 0.8):]\n",
    "\n",
    "    \n",
    "    \n",
    "    train = data.iloc[train_indices] \n",
    "    validation = data.iloc[validation_indices] \n",
    "    test = data.iloc[test_indices]\n",
    "    \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train, valid, test = train_val_test_split(vehicles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627814bb",
   "metadata": {},
   "source": [
    "Checking that they add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train) + len(test) +len(valid) == len(vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of training set:\", len(train))\n",
    "print(\"length of validation set:\", len(valid))\n",
    "print(\"length of testing set:\", len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f6420",
   "metadata": {},
   "source": [
    "### Train/Test/Validation Split Using SKLearn\n",
    "\n",
    "We can use the `train_test_split` function from `sklearn.model_selection` to do this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552154d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of full dataset: 392 points\n",
      "Size of training set: 313 points\n",
      "Size of test set: 79 points\n",
      "Size of original training set: 313 points\n",
      "Size of mini training set: 250 points\n",
      "Size of validation set: 63 points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# `test_size` specifies the proportion of the full dataset that should be allocated to testing.\n",
    "# `random_state` makes our results reproducible for educational purposes.\n",
    "# shuffle is True by default and randomizes the data before splitting.\n",
    "\n",
    "\n",
    "X = vehicles\n",
    "\n",
    "\n",
    "Y = vehicles[\"mpg\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=100, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "print(f\"Size of full dataset: {X.shape[0]} points\")\n",
    "print(f\"Size of training set: {X_train.shape[0]} points\")\n",
    "print(f\"Size of test set: {X_test.shape[0]} points\")\n",
    "\n",
    "\n",
    "# Split X_train further into X_train_mini and X_val.\n",
    "X_train_mini, X_val, Y_train_mini, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=13)\n",
    "\n",
    "print(f\"Size of original training set: {X_train.shape[0]} points\")\n",
    "print(f\"Size of mini training set: {X_train_mini.shape[0]} points\")\n",
    "print(f\"Size of validation set: {X_val.shape[0]} points\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564866d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b296abe",
   "metadata": {},
   "source": [
    "## Fitting Models Using Training Data and Evaluating RMSE Using Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27160655-4f96-4925-afde-647b66411318",
   "metadata": {},
   "source": [
    "In the cell below, we fit several models of increasing complexity (using the training data), then compute their errors. Here, we find the model's errors on the **validation set** to understand how model complexity influences performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09947a6f-a2df-46d5-8549-949b58ae12a6",
   "metadata": {},
   "source": [
    "Outline of code below:\n",
    "\n",
    "1. Fit an degree-x model to the mini training set\n",
    "2. Evaluate the fitted model's RMSE when making predictions on the validation set\n",
    "\n",
    "We use the model's performance on the validation set as a guide to selecting the best combination of features. We are not limited in the number of times we use the validation set – we just never use this set to fit the model.\n",
    "\n",
    "\n",
    "The code below uses `Pipelines` in scikit-learn.  For the scope of CSCI 3022 this semester, you do not need to know how to use sci-kit learn's `Pipeline` class - it is quite involved. Fortunately, they are merely an accessory to the concepts of this lecture, and not the core of it. If you treat each instance of a `Pipeline` as a black-box way of specifying which features our model should have, you will be able to understand the cross-validation content just fine.\n",
    "\n",
    "If you're interested, you can [skim the documentation on pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3caecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f95381bfb50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAGyCAYAAACbVR4mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABJ0AAASdAHeZh94AABn5UlEQVR4nO3deXxcdb3/8ddnJmmatknTLaEU2kJZulGkgFAQWhZFEC4iKIIVCuWicq+Xi4jiwiKgPxT1ulFAaUFWEaUgi6CsRQVUCnRjh7ZAadIt6ZakWb6/P75nkpPJbEknmZnk/Xw85jFnzvmecz6zZOaT73bMOYeIiIiI9C+RXAcgIiIiIr1PSaCIiIhIP6QkUERERKQfUhIoIiIi0g8pCRQRERHph5QEioiIiPRDSgJFRERE+iElgSIiIiL9kJJAERERkX6oKNcB5DMzGwrMBN4DduQ4HBEREZFUBgC7A8845+rSFVYSmNpM4IFcByEiIiLSBScDf0pXSElgau8B3H///ey11165jkVEREQkqbfeeotPf/rTEOQv6SgJTG0HwF577cWUKVNyHYuIiIhIJjLqwqaBISIiIiL9kJJAERERkX5ISaCIiIhIP6QkUERERKQfUhIoIiIi0g9pdLCIiEiWtLa2Ul1dTWNjI62trbkOR/oAM6O4uJjy8nLKysows6wdW0mgiIhIFrS2trJ69Wrq6+uJRqNEo9Gs/mBL/+Oco6WlhYaGBrZs2cKgQYMYM2YMRUXZSd+UBIqIiGRBdXU19fX1DB8+nMrKSiWAkjXNzc3U1NRQV1fHpk2bGDVqVFaOqz6BIiIiWdDY2Eg0GlUCKFlXVFTE6NGjiUajbN26NWvHVRIoIiKSBa2trWoClh5jZkSjUZxzWTumkkAREZEsUQIoPSnbny8lgSIiIiL9kAaG5NL2jbD8PqheAQeeDaP3z3VEIiIi0k+oJjCXdmyDhy+Gf8+H1c/nOhoREZFOTjnlFEpLS6mtrU1a5gtf+ALFxcVUV1dnfFwz48orr8yoXPhWXl7OYYcdxt13392p7K233tpW7umnn+603TnHXnvthZkxa9asDts2bNjAt771LSZPnszgwYMZOnQoEydO5Itf/CJLlixJeI5Et0TnzVeqCcylobtBSTk0boaaFbmORkREpJO5c+dy//33c9ddd3HBBRd02l5XV8fChQs58cQTqaqq6pEYTjvtNC6++GKcc7z77rv84Ac/4Mwzz8Q5x5lnntmpfFlZGfPnz++U6D3zzDO8/fbblJWVdVi/detWDj30ULZu3coll1zC/vvvT319PW+88Qb33XcfL7/8MtOmTeuwzy233MLEiRM7nXvy5Mk7/4R7iZLAXDKDyknw3gu+SVhERCTPHH/88ey6664sWLAgYRJ49913U19fz9y5c3sshqqqKg499FAAZsyYweGHH8748eO56aabEiaBp59+OnfeeSfXX3895eXlbevnz5/PjBkz2Lx5c4fy9957L2+99RZPPvkkRx11VIdtX/va1xJe/WXq1KkcdNBB2Xh6OaPm4FyrDP5jqHkVsjjsW0REJBui0Shnn302L774IkuXLu20/ZZbbmH06NEcf/zxrFu3jgsuuIDJkyczZMgQKisrOfroo3n22WezGtO4ceMYNWpU0ubnM844A6BDk3FdXR1//OMfOffcczuV37BhAwCjR49OeLxIpG+mS6oJzLVYErhjC9S9BxVjcxuPiIhk3fceXM6KNZvTF+wFk3ct54qTpnRpn3PPPZdrr72WBQsW8H//939t61esWME///lPLr30UqLRKBs3bgTgiiuuYJdddmHr1q0sXLiQWbNm8cQTT3Rqnu2uuro6Nm7c2FY7GK+8vJzTTjuNBQsW8KUvfQnwCWEkEuH000/nZz/7WYfyM2bMAOCss87i29/+NkcccQQjRoxIGUNLSwvNzc0d1sXm8isUSgJzrSrUd6B6hZJAEZE+aMWazbzw7sZch9Fte+21F0ceeSR33HEHP/rRjyguLgZgwYIFAG21a/vuuy/z5s1r26+lpYXjjjuOlStX8otf/KLbSaBzjubmZpxzrFy5kq9//esMGjSIK664Iuk+5557LkcddRTLly9nypQpLFiwgM9+9rOd+gMCHH744Vx11VVcc801nHLKKQDsscceHHfccXzlK1/p1B8QSJiARqPRTolhPlMSmGuVoSSwZgXs+8ncxSIiIj1i8q7l6Qv1ku7GMnfuXM466yz+9Kc/ceqpp9Lc3Mwdd9zBEUccwd57791W7sYbb+TXv/41K1asoLGxsW19okEUmZo3b16H5LK4uJiFCxdy4IEHJt1n5syZTJgwgQULFjBnzhz+9a9/8ZOf/CRp+csuu4zzzz+fRx55hBdeeIF//OMf3Hjjjdx8883cdtttbU3MMbfddhuTJk3qsK7QJgtXEphrg4bDkF1g61qNEBYR6aO62vyaj0477TS++tWvcsstt3DqqafyyCOPUF1dzQ9/+MO2Mj/96U+5+OKL+fKXv8zVV1/NyJEjiUajXHbZZbz66qvdPvfnPvc5LrnkEpqamli6dCnf+ta3+PznP8/ixYs7JKBhZsY555zDL37xCxoaGthnn3044ogjUp6nqqqKc845h3POOQeARYsWcfzxx3PhhRd2SgInTZqkgSHZZmYHmNn9ZrbGzLab2WtmdrmZDcpg30ozu9XM1gf7Pmdmx/RG3Dsl1iSsEcIiIpKnSktLOeOMM3j00Uf58MMPWbBgAWVlZXz2s59tK3PHHXcwa9YsbrjhBj71qU9xyCGHcNBBB7Fly5adOveoUaM46KCDmDFjBueffz73338/27Zt46KLLkq535w5c1i/fj033nhjW2LXFUceeSSf+MQnWLduHTU1Nd0NP2/lVRJoZpOBfwDjgf8FTgR+B1wOdJ4VsuO+JcATwDHAhcDJQDXwqJnN7LGgsyHWJLz+DWhpym0sIiIiScydO5eWlhauu+46HnnkET7/+c8zaFB7HY2ZUVJS0mGfJUuW8Nxzz2U1jiOOOIKzzjqLhx9+OOWxx4wZwyWXXMJJJ53E2WefnbRcdXV1wmlgWlpaePPNNxk0aBAVFRXZCD2v5Ftz8JnAQOBU59zbwbonzWw0cL6ZDXPObUqy71xgKnCYc+45ADN7CngF+BFwSM+GvhNiSWBrE2x4y88dKCIikmcOOuggpk2bxs9+9jOcc53mBjzxxBO5+uqrueKKK5g5cyavv/46V111FXvssUfWB0xcffXV3HPPPVx22WU8/vjjSctde+21aY91++23t805ePDBBzN06FDef/99br75ZpYvX87ll1/OgAEDOuyzbNmyhM9pwoQJjBo1qutPKAfyLQmMVYPVxa2vBVqBHSn2PQV4PZYAAjjnms3sDuAHZjbGOfdBNoPNmqq4wSFKAkVEJE/NnTuXCy+8kMmTJ3PIIR3rV77zne+wfft25s+fz49+9CMmT57MjTfeyMKFC7N+ObXdd9+dr371q1x33XUsWrSII488stvH+tSnPsXatWt55JFHuOGGG9i0aRNlZWVMmzaN22+/ndmzZ3faJ1nz8m9+8xvOO++8bsfSm8zl0QTFZjYeeAl4HPgmsA6YCdwB3Oac+58U+34IPOuc+1zc+k8BDwHHOef+kmL/SiA+dZ8APLBs2TKmTOnBTr07tsMPdgUcHPF1OOaynjuXiIj0iHfeeQeAPffcM8eRSF+V7jO2fPlypk6dCjDVObc83fHyqibQObfSzGYAC4G3Q5t+ge8jmMoIINEkTBtD21O5AEg+4VBPGjAIhu8JG9/WCGERERHpFXmVBAY1gQ/iB3Schq8JPAT4LjAE3+8vlVTVmumqPOcB98atmwA8kGa/7KicpCRQREREek1eJYHAtUA58BHn3LZg3SIzWw8sMLPbnHPPJNl3A4lr+4YH9ymnanfO1QAdxn/36qSPVVPgtYdg00po3AolQ3rv3CIiItLv5NUUMcBHgBWhBDDmX8H91BT7LgX2S7A+tm7ZzoXWw8JXDln3eu7iEBERkX4h35LANcAUM4uvBpsR3L+fYt+FwEQzaxuqZGZFwGzgBefcmqxGmm0dLh+Xti+niIiIyE7JtyTwZ8BI4K9m9jkzO9rMvg38FFgB/BnAzOabWbOZjQvtuwBYDtxrZmea2bHA74F98SON89vwPSEaTLCpK4eIiIhID8urJNA59yf8FT82Az/HT+1yNnATcKRzLjZPYDS4WWjfxmDfp4Bf4geYjAaOT9GPMH9Ei2DUvn5Zg0NERESkh+XbwBCcc0/hE7lUZeYAcxKsr8YnjYWpcjKsXaIkUERERHpcXtUE9nuxK4dsWwdb1+U2FhEREenTlATmk8q4y8eJiIiI9BAlgflESaCIiOQZM8votrPXBr7yyiuzPj9vfIzl5eUcdthh3H333Z3K3nrrrSmfi3OOvfbaCzNj1qxZHbZt2LCBb33rW0yePJnBgwczdOhQJk6cyBe/+EWWLFmS8Bw98Rp2Vd71CezXyneFgUOhoU5JoIiI5IXnnnuuw+Orr76ap556iieffLLD+smTJ7MzzjvvPD75yU/u1DESOe2007j44otxzvHuu+/ygx/8gDPPPBPnHGeeeWan8mVlZcyfP79TovfMM8/w9ttvU1ZW1mH91q1bOfTQQ9m6dSuXXHIJ+++/P/X19bzxxhvcd999vPzyy0ybNq3DPrfccgsTJ07sdO6dfQ27SklgPjHztYGrn9M0MSIikhcOPfTQDo9HjRpFJBLptD7e9u3bGTRoUMbn2W233dhtt926FWMqVVVVbbHOmDGDww8/nPHjx3PTTTclTAJPP/107rzzTq6//nrKy8vb1s+fP58ZM2awefPmDuXvvfde3nrrLZ588kmOOuqoDtu+9rWv0dra2ukcU6dO5aCDDsrG09spag7ON7Em4ZpXIcEHR0REJN/MmjWLqVOnsmjRIg477DAGDRrEueeeC8A999zDJz7xCUaPHk1paSmTJk3i0ksvZdu2jhcHS9QcPH78eE488UQeffRRpk+fTmlpKRMnTmTBggXdjnXcuHGMGjWK6urqhNvPOOMMgA5NxnV1dfzxj39se05hGzZsAGD06NEJjxeJ5G+qlb+R9VeVk/x90zaoW53bWERERDL04YcfMnv2bM4880weeeQRLrjgAgDefPNNTjjhBObPn8+jjz7K//7v//L73/+ek046KaPjvvLKK1x88cVcdNFFPPDAA0ybNo25c+eyaNGibsVZV1fHxo0b2WeffRJuLy8v57TTTuuQaN59991EIhFOP/30TuVnzPAXNTvrrLO4//7725LCVFpaWmhubu5wa2lp6dbz2RlqDs43VVPal6tXwLDxOQtFRESy5M+XwtqluY7C22U/OP7arB9248aN3HvvvRx99NEd1n/3u99tW3bOcfjhhzNp0iRmzpzJkiVLOvWXi7d+/Xr+/ve/M3bsWACOPPJInnjiCe666y6OPPLItHE552hubsY5x8qVK/n617/OoEGDuOKKK5Luc+6553LUUUexfPlypkyZwoIFC/jsZz/bqT8gwOGHH85VV13FNddcwymnnALAHnvswXHHHcdXvvKVhM8vUVN6NBqlubk57fPJJiWB+SZWEwh+cMjEE3IXi4iIZMfapbDqb7mOokcNGzasUwII8M477/Dd736XJ598kpqaGpxzbdteffXVtEngRz7ykbYEEGDgwIHss88+rFq1KqO45s2bx7x589oeFxcXs3DhQg488MCk+8ycOZMJEyawYMEC5syZw7/+9S9+8pOfJC1/2WWXcf755/PII4/wwgsv8I9//IMbb7yRm2++mdtuu62tiTnmtttuY9KkSR3WZXtkdCaUBOab0mFQtitsWaMRwiIifcUu++U6gnY9FEuiPnFbt27liCOOYODAgVxzzTXss88+DBo0iPfee4/PfOYz1NfXpz3uiBEjOq0rKSnJaF+Az33uc1xyySU0NTWxdOlSvvWtb/H5z3+exYsXs/feeyfcx8w455xz+MUvfkFDQwP77LMPRxxxRMrzVFVVcc4553DOOecAsGjRIo4//nguvPDCTkngpEmT8mJgiJLAfFQ12SeBGiEsItI39EDza75JVJP15JNPsmbNGp5++mlmzpzZtr62trbX4ho1alRbwjVjxoy2puiLLrqIhx56KOl+c+bM4fLLL+fGG2/k+9//fpfPe+SRR/KJT3yC+++/n5qaGiorK7v9HHqKBobko9gI4Q1vQvOO3MYiIiLSTbHEsKSkpMP6m266KRfhAHDEEUdw1lln8fDDD3eaAzFszJgxXHLJJZx00kmcffbZSctVV1cnnAampaWFN998k0GDBlFRUZGN0LNONYH5KJYEtjb7RDA8WERERKRAHHbYYQwbNowvf/nLXHHFFRQXF3PnnXfyyiuv5DSuq6++mnvuuYfLLruMxx9/PGm5a69NX4N7++23t805ePDBBzN06FDef/99br75ZpYvX87ll1/OgAEDOuyzbNmyhINAJkyYwKhRo7r+hLpJSWA+qgpfPu5VJYEiIlKQRowYwcMPP8zFF1/M7NmzGTx4MCeffDL33HMP06dPz1lcu+++O1/96le57rrrWLRoUUajjJP51Kc+xdq1a3nkkUe44YYb2LRpE2VlZUybNo3bb7+d2bNnd9on1m8w3m9+8xvOO++8bsfSVRYepSMdmdkUYNmyZcuYMqUXE7GmevjBruBa4WNfg2OTD2MXEZH88M477wCw55575jgS6avSfcaWL1/O1KlTAaY655anO576BOaj4lIYPsEva4SwiIiI9AAlgfkq1iSsJFBERER6gJLAfBUbHFK7Ghq35DYWERER6XOUBOaryvDgkNdyF4eIiIj0SUoC81WHJDBt304REckDGmwpPSnbny8lgflq+B5QVOqXdeUQEZG8F4lEaGlpUSIoPcI5R0tLS1avMawkMF9FojBqX7+swSEiInmvpKSElpYWampqlAhKVjU3N/Phhx/S0tLCkCFDsnZcTRadzyonw4cv+yTQOchi9i8iItlVVVVFY2MjGzdupK6ujmg0mtVaG+l/nHO0tra2XV1k0KBBDBs2LGvHVxKYz2LTxGzfAFtroKwqt/GIiEhSkUiEsWPHUl1dTWNjY8LryYp0hZlRVFREaWkp5eXllJWVZfUfCyWB+azD4JAVSgJFRPJcJBJh9OjRuQ5DJCPqE5jP4pNAERERkSxREpjPynaB0qDtX0mgiIiIZJGSwHxm1l4bqGliREREJIvyKgk0s1vNzKW4HZpi3zkp9tulN59HVsWSwHWvgToZi4iISJbk28CQq4EbE6x/EGgE/pXBMc4B4q+ztmEn48qd2Ajhpu1QuxKG75nTcERERKRvyKsk0Dn3NvB2eJ2ZzQRGAtc451oyOMwy59y/eyK+nAgPDqleoSRQREREsiKvmoOTmAs4YEGuA8mJykntyzWv5i4OERER6VPyqiYwnpkNBU4DnnDOvZvhbg+Z2SigDngauNw5tyyDc1UCo+JWT+hCuD1j4FAo3w02vw81y3MdjYiIiPQReZ0EAmcApcD8DMquBb4PPA9sBvYDLgWeN7PDnXOvpNn/AuCKnYi151RN9kmgRgiLiIhIluR7EjgXP6hjYbqCzrlHgUdDqxaZ2cPAUuAq4OQ0h5gH3Bu3bgLwQMbR9pTKyfDmX2DDW9DcCEUluY5IREREClzeJoFmNg04CPi5c66xO8dwzq00s78BSaeWCZWtAWriYujOabMvNjjEtcD6N2CX/XIbj4iIiBS8fB4YMje4v3knj2NAYU+wVxW+fJwGh4iIiMjOy8sk0MxKgNnAPzMZ1JHiOHsAh+P7CRaukfuARf1ytQaHiIiIyM7LyyQQ+DQwnCS1gGY238yazWxcaN3jZna5mX3azI42swuBv+Gnl7msN4LuMUUlMGIvv6xrCIuIiEgW5GufwLnANuB3SbZHg1u4095S4HTg6/gRxTXAk8DVzrk3ei7UXlI1Gda/ruZgERERyYq8TAKdc59Is30OMCdu3UU9GFLuVU6G5Quh7j1oqPPzB4qIiIh0U742B0u8Sg0OERERkexRElgoOowQVr9AERER2TlKAgtFxXgoHuSXdeUQERER2UlKAgtFJAKjJvplNQeLiIjITlISWEhi/QJrloNzuY1FRERECpqSwEIS6xdYvwm2rM1tLCIiIlLQlAQWkkoNDhEREZHsUBJYSJQEioiISJYoCSwkQyph0Ai/rMEhIiIishOUBBYSs/bawOrluY1FRERECpqSwEITSwLXvQatLbmNRURERAqWksAcW1Nbz0NL1lCzpSGzHWIjhJsbYNPKHotLRERE+jYlgTm07IM6Drv2Sf77rpf425vrM9spPDhETcIiIiLSTUoCc2jfXcoYWOzfgsWrN2W2U+Wk9mUNDhEREZFuUhKYQ8XRCNPGVACweFVtZjuVlEHFWL9co5pAERER6R4lgTk2fdwwAF5bu5ltjc2Z7dQ2QlhzBYqIiEj3KAnMseljKwBodfDKe7WZ7RRLAje+DU0ZDigRERERCVESmGOxmkDoSr/AIAl0rbD+9R6ISkRERPo6JYE5NnJICWOHDwJg8erazHaqCo8QVpOwiIiIdJ2SwDwQaxJ+afUmnHPpdxixN0SK/LKuISwiIiLdoCQwDxwYNAlv2t7Eu+u3pd+haIBPBEFJoIiIiHSLksA8cMDY9n6BL67KsF9grElYcwWKiIhINygJzAMTdylj0IAo0IV+gbFJozd/APUZJo4iIiIiASWBeaAoGmHabkMB3y8wI5VT2pdVGygiIiJdpCQwT8T6Bb5evYUtDU3pdwiPEFa/QBEREekiJYF5YnrQL9A5eDmTSaOHjoXiwX5Z08SIiIhIFykJzBPhwSEZXUc4EmnvF6jmYBEREekiJYF5YvjgAewx0tfsZXzlkLYRwst9FaKIiIhIhvIqCTSzW83Mpbgdmmb/yuAY681su5k9Z2bH9Fb8O+uA0KTRra0ZJHWxy8c11MHmNT0XmIiIiPQ5eZUEAlcDMxLc1gMfAP9KtqOZlQBPAMcAFwInA9XAo2Y2s2fDzo7Y4JDNDc28s35r+h0qw4ND1CQsIiIimSvKdQBhzrm3gbfD64IEbiRwjXOuJcXuc4GpwGHOueeCfZ8CXgF+BBzSI0Fn0fS4SaP3qixLvUOHJHA57H1sD0UmIiIifU2+1QQmMhdwwII05U4BXo8lgADOuWbgDuCjZjam50LMjn2qyhhS4vPyjAaHDBkFg0f5ZdUEioiISBfkdRJoZkOB04AnnHPvpik+FViSYH1s3ZQE28LnqjSzKeEbMKHLQe+EaMTYf3c/aXTGg0NitYHVy3soKhEREemL8joJBM4ASoH5GZQdAWxMsH5jaHsqFwDL4m4PZBZm9sSahN+s2UpdfQaTRseSwHWvQ0tzD0YmIiIifUm+J4FzgQ3AwgzLpxpSm2647Tx8bWL4dnKG582a6ePa+wVmNGl0bJqYlkbYlK6yVERERMTL2yTQzKYBBwF3OOcaM9hlA4lr+4YH94lqCds452qcc8vDN+IGqfSG6bt3HBySVnhwiJqERUREJEN5mwTiawEBbs6w/FJgvwTrY+uW7XREvWDooGImjPKTRr+USb/AURPbl3UNYREREclQXiaBwZx/s4F/OucyTd4WAhPNrG0qGDMrCo7zgnOuYGZTjvULfHl1bfpJo0uGwLDxfllJoIiIiGQoL5NA4NP4ZtyEtYBmNt/Mms1sXGj1AmA5cK+ZnWlmxwK/B/YFvtnD8WZVbNLoLY3NvFnThUmjq5UEioiISGbyNQmcC2wDfpdkezS4WWxF0G/wGOAp4JfAg8Bo4Hjn3DM9Gm2WhQeHdKlf4MZ3oKm+h6ISERGRviQvk0Dn3Cecc0Occ1uSbJ/jnDPn3Mq49dXOubOdcyOcc6XOuRnOucd7Jegs2mvUEMoGBpNGZ9IvMDZCGAfrXuu5wERERKTPyMsksL+LRIyP7F4BZJgEdhghrCZhERERSU9JYJ6KDQ55Z902arfvSF14xF4QKfbLGhwiIiIiGVASmKcODPULfGl1berC0WIYuY9fVhIoIiIiGVASmKc+MrYCC4a9ZDQ4JNYvsObVngtKRERE+gwlgXmqfGAxe1cOAbrYL3DLh7A95cVRRERERJQE5rNYv8BX3qulJd2k0eHBIWoSFhERkTSUBOaxWBK4bUcLr69NOFtOu6pwEqgmYREREUlNSWAeC08anbZJeOjuMKDML1cv78GoREREpC9QEpjH9hw5mKGlfuqXxekGh5hB5SS/rJpAERERSUNJYB6LRIwDxlYAXbxySM2r4NL0IRQREZF+TUlgnov1C1y5YTsbtjamLhwbHNJYB3Xv93BkIiIiUsiUBOa5Lk0aXanBISIiIpIZJYF5bv/dK4jEJo1O1yTcIQnU4BARERFJTklgnhtSUsQ+VX7Ub9rBIYNHwJAqv1ytuQJFREQkOSWBBSA2VcyS9+tobmlNXbhSl48TERGR9JQEFoDY4JD6phZeSzdpdCwJXP86tDT1cGQiIiJSqJQEFoADuzJpdGyamJYdsPGdHoxKRERECpmSwAIwfsQghg8eAMCL6foFhgeH6MohIiIikoSSwAJgZhywewWQQU3gqIlAMJy4RoNDREREJDElgQUiNjjkvY31rNuSYtLoAYNg+B5+WYNDREREJAklgQUidvk4yKA2MNYkrOZgERERSUJJYIHYf7cKosGs0RkngZtWwo5tPRuYiIiIFCQlgQVicEkRE3fJcNLo2AhhHKx7rWcDExERkYKkJLCAxOYLXPJ+HTuaU0wa3WGEsAaHiIiISGdKAgvI9HEVADQ2t/Lqh5uTFxw+AaIlflmDQ0RERCQBJYEF5MCxw9uWU/YLjBbBqH38co0Gh4iIiEhnSgILyO7DSxk5xE8avXh1berCuoawiIiIpJCXSaCZfczMHjGzTWZWb2ZvmtllafaZY2YuyW2X3oq9J5kZBwT9AtMODoklgVurYduGHo5MRERECk3eJYFmdibwDFAHnAWcAPyQtstgpHUOMCPu1meyoNjgkA9q66ne3JC8YHhwiJqERUREJE5RrgMIM7MxwK+Bm5xzF4Q2PdWFwyxzzv07u5Hlj+nhSaNXbeL4/UYnLlgVTgJfhT2O7NnAREREpKDkW03gecBgfM2fJDBttwqKMpk0unwMlAz1y7pyiIiIiMTJtyTwSGAjMNHMXjazZjOrMbMbzaw8w2M8ZGYtZrbRzO4zs6k9GG+vKx0QZfKu/qV4MVW/QDOonOSXazRXoIiIiHSUb0ngGGAQcC9wD3AscB2+b+AjZpaqX+Ba4Pv42sSjgMuAg4HnzWz/dCc2s0ozmxK+ARN26tn0kFi/wGUfbKaxuSV5warQCGHneiEyERERKRR51ScQn5QOBL7nnLs2WPe0me0AfgYcAzyeaEfn3KPAo6FVi8zsYWApcBVwcppzXwBc0f3Qe88BYyu49R+wo6WV5Ws2tyWFncQGh+zYCrWrYdi43gtSRERE8lq+1QTGRvE+Frf+z8H99K4czDm3EvgbcGgGxecBU+Nu6RLHnAgnfSmniqmMGxwiIiIiEsi3JHBJkvWxZuAUF8xNyjLZzzlX45xbHr4Bb3fjfD1ut2GlVJb5y8K9lGrS6FifQNA0MSIiItJBviWBfwzuj49bf0Jw/3xXDmZmewCHd3W/fGdmbbWBKQeHDBoOZcEUMtUaHCIiIiLt8qpPoHPuL2b2IHC5mUXwydtB+L56Dznn/gZgZvOBs4EJzrlVwbrHgUX42sTNwH7ANwCHHyTSp0wfV8Gjy9eydnMDa2rr2bWiNHHBysmw5UM1B4uIiEgH+VYTCHA6fhDI+fi+gF8B/g84LVQmGtzCo4WXBvvehu9T+A3gSeAg59yyHo+6l3XoF5hqvsDYCOH1b0BLUw9HJSIiIoUir2oCAZxz9cClwS1ZmTnAnLh1F/VoYHlm6pihFEeNphbH4lW1nDht18QFY4NDWptgw1sd+wmKiIhIv5WPNYGSgYHFUabs6q8IkrImMDxCWFcOERERkYCSwAIWaxJevqaOhqYkk0aP2hcseJt15RAREREJKAksYNPHVQDQ1OJY9kFd4kLFpTB8T7+swSEiIiIS6PEkMBjlKz0g48EhsSZhNQeLiIhIoFsJmpm9E74er3m/NrPd48odAmhIag/ZtaKU0UMHArB4VW3ygrEksHYVNG7t+cBEREQk73W3lm48UBJ3nLnAqJ0NSLqmbdLo1ZtwziUuVBUaHLLutV6ISkRERPJdNptqLX0RybYDxlYAsG5LI+9vqk9cSCOERUREJI766xW46eMy6Bc4fE8o8s3GGhwiIiIioCSw4E3ZtZwBRf5tfGl1beJCkaifKgagRjWBIiIisnNJYKIOaEk6pUlPKSmKst+YLkwaXa25AkVERGTnLht3l5nFd0K7x8waQo9Ld+L4kqHpYyt4cdUmVqzZTP2OFkoHRDsXiiWB29fD1nUwRGN4RERE+rPuJoGL6Fzr90ySsu938xySIT9C+F2aWx1L3q/lkD1HdC4UHiFcsxyGzOqt8ERERCQPdSsJdM7NynIcshM6Dg5JkgSGRwjXvAp7zur5wERERCRvaWBIH1BVPpAxFb7lPWm/wLLRMLDCL2uaGBERkX4vq0mgmQ03s2vN7CEzu8nMpmTz+JJcrDbwpWSTRpu11wbWaHCIiIhIf9fdy8b92MxWx60bDPwLuAQ4AfhP4B9mtu9ORylpTQ8mjV6/dQerN25PXCjWL7DmNWht7Z3AREREJC91tybwMOB3cev+G9gD+BlQEZTZClzazXNIF8QuHwcpmoRjNYFN2/x1hEVERKTf6m4SuCfw77h1JwHrgG845zY7554HfgrM6n54kqlJo8spCSaNXryqNnGh+MEhIiIi0m91NwmsAD6MPTCzIuBg4GnnXEuo3EvA6G5HJxkbUBRh/90qgFQ1gZPal3XlEBERkX6tu0lgNR2Tu+lAMZ1rB1uBxm6eQ7rogHEVALz64Wa2NTZ3LlBaAeVj/LKuHCIiItKvdTcJfBH4TzOz4PEX8JNHPxFXbiKhGkPpWbF+ga0OXnm/NnGhthHCag4WERHpz7qbBP4QOAp43cz+AXwV+JtzbnFcuZPwI4alF4QHh7y0ujZxodgI4Q1vQvOOng9KRERE8lK3kkDn3AvAycAaoAy4GTglXMbMdgF2Ax7YyRglQ6PKShg7fBAAi1elGSHc2uwTQREREemXunvtYJxzDwMPp9i+Fti/u8eX7pk+toLVG7ezOJg0ur3FPhAeIVy9Aqo0n7eIiEh/pMvG9TGxK4ds2t7Eu+u3dS4wch+wqF/WCGEREZF+q1s1gWZ2VlfKO+du6855pOs6Thpdy56jhnQsUDwQRkyA9W9ocIiIiEg/1t3m4Fvxo4EBLEU5gnJKAnvJxF3KKC2OUt/UwuLVmzjtwN06F6qc7JNATRMjIiLSb3W7TyCwGbgHf/m4LdkJR3ZWUTTC/rsP5fl3NqYeHLLifqhbDQ2bYWB5r8YoIiIiudfdPoEzgfuB2cCDwH8Bpc65FxPdunpwM/uYmT1iZpvMrN7M3jSzyzLYr9LMbjWz9Wa23cyeM7Njunr+QhdrEn6jegtbGpo6F6gKDQ5Z91ovRSUiIiL5pLtTxDzrnDsH2AX4GjAJWGRmb5jZN82s25eKM7MzgWeAOuAs4AT8vIQpm53NrAQ/WfUxwIX4KWyqgUfNbGZ34ylEHSaNfq+uc4EOI4Q1OERERKQ/2qnRwc65rc653zjnZgBT8bWCXwNWmdk1XT2emY0Bfg3c5Jw7wzn3oHPuKefczc65q9LsPjeI4XPOuTudc38FTgPeAH7U1VgK2QFjK9qWE15HeNh4KCr1yxocIiIi0i9lbYoY59wKYAHw++C4k1PvkdB5wGB8zV9XnQK87px7LhRTM3AH8NEgwewXRgwpYfyIYNLoRElgJAqVE/1yjQaHiIiI9Ec7nQSaWbmZfcnMXgCWAB8HvovvJ9hVRwIbgYlm9rKZNZtZjZndaGbpRi9MDc4fL7Yu5azIQX/CKeEbMKHLzyBPxOYLfGl1La2trnOBWJNw9XJwCbaLiIhIn9btJNDMjjKz24G1wI+BFcAs59xE59y1zrkPu3HYMcAg4F78yONjgevwfQMfsU6Xv+hgBD6BjLcxtD2VC4BlcbeCveRdrF9gXX0T76zf2rlALAms3whba3oxMhEREckH3Z0s+i1gD+B54KvA75xzCS5P0WURYCDwPefctcG6p81sB/Az/KCPx1Psn6pKK1111zx88hk2gQJNBDtMGr2qlr0qyzoWCI8QrlkOZVW9FJmIiIjkg+7WBO6JnxuwDD8S9zkzW5Lk9koXjrshuH8sbv2fg/vpafZNVNs3PLhPVEvYxjlX45xbHr4Bb6cLOF/tu0sZgwf4y8Ml7BcYHiGswSEiIiL9Tncni15E+pq17lgCHJpgfawZuDXFvkuB/RKsj61bthNxFZxoxPjI2Ar+/taGxEngkCooHe6bg3XlEBERkX6nW0mgc25WpmXT9OOL90fgfOB44KXQ+hOC++dT7LsQmGdmhzjnXgjOXYSf0PoF59yaLsTRJ0wfO4y/v7WBN2u2UlffxNDS4vaNZr42cNXffHOwiIiI9CtZmyImkWDi54yrmZxzf8HPNXi5mX3XzI41s0uBHwAPOef+Fhx3fjByeFxo9wXAcuBeMzvTzI7FT1ezL/DNLD2lghLrF+gcvPxebecCsX6BNa9Ba6pKVhEREelrdmZ08FAzO9vMvmFmnzazSGjbZ8xsGX6OvtIuHvp0/CCQ8/F9Ab8C/B9+4ueYaHBrq2V0zjXiB448BfwSn0yOBo53zj3TxRj6hA6TRie6jnCsX2BzPWx6t3eCEhERkbzQ3dHBewHPApX4RMwBz5jZp4G7gU8CtcA38AlZxpxz9cClwS1ZmTnAnATrq4Gzu3K+vqxi0AD2HDWYd9Zty2xwyIiCnRZRREREuqi7NYFXA+XAlcCngP8BJgL/wPfnmw9McM79OKihkxw5MGgSfvm9BJNGV05qX9aVQ0RERPqV7iaBM4FrnHNXO+f+7Jy7HjgHf6m4G51z5zvnarMVpHRf7MohWxqaeWtd3KTRA8th6Fi/XK3BISIiIv1Jd5PAUcDf49b9Lbi/p/vhSLaFJ41+MWG/wKA2UHMFioiI9CvdTQKjQEPcutjjLd0PR7Jt78ohlJX4rp8JB4fERghveAua1XIvIiLSX3R3smiAfc2sOfQ4GtxPjJ8a0Dm3eCfOIzshEkwa/eyb61MPDnEtsO51GD2tdwMUERGRnNiZJPDWJOtvDy3HRg5Hk5SVXjB97DCefXM9b6/bRu32HVQMGtC+MX6EsJJAERGRfqG7SeA5WY1CelRscAjAS+/VctS+le0bR+4DkSJobdaVQ0RERPqR7l427rfZDkR6zkd2r2hbXrxqU8cksGgAjNgL1r2mwSEiIiL9SI9eNk7yw9DSYvauHAKQul9gteYKFBER6S+UBPYTBwZNwi+vrqWl06TRQRK4+X2or+3dwERERCQnlAT2E7H5ArftaOGN6rhZfKpCg0PWvdaLUYmIiEiuKAnsJ6aPq2hb7jRpdHiEsK4cIiIi0i8oCewn9hw5hPKBwaTR8f0CK8ZB8WC/rMEhIiIi/YKSwH4iEjEOCJqEX1pdG78RKif65RoNDhEREekPlAT2I7HBIe+u38bGbTs6bmwbIbwcXNzAEREREelzlAT2I7HBIQAvxTcJx5LAhlrYsrb3ghIREZGcUBLYj+y/+1Bil3XuNDgkPEJYVw4RERHp85QE9iNlA4vZt6oMSDA4JP4awiIiItKnKQnsZ2KDQ155r47mltb2DUMqYdBIv6wrh4iIiPR5SgL7mdjgkPqmFl5bm2TSaDUHi4iI9HlKAvuZ6WMr2paTDg5Z9zq0tvReUCIiItLrlAT2M3uMHMywQcVAiiuHNDfAxnd7OTIRERHpTUoC+xmz9kmjF8dPGl2pEcIiIiL9hZLAfijWL3D1xu2s39rYviF21RDQCGEREZE+TklgP3RAqF/g4nCTcEmZv44w+CuHiIiISJ+lJLAf2n+3CiKxSaOTDQ5RTaCIiEifpiSwHxpcUsTEXcoBeGlVbceNsWliNr4NTfW9G5iIiIj0GiWB/dT0cRUALPmglqbwpNGxmkDX6qeKERERkT4pr5JAM5tlZi7J7dA0+85Jse8uvfUcCkVscEhDUyuvfri5fYMuHyciItIvFOU6gCS+DTwVt25ZhvueA7wWt27DTkfUx0wPpokBPzhk2m4V/sGIvSBSDK1NmiZGRESkD8vXJPBN59zz3dx3mXPu31mNpg8aO3wQIwYPYMO2Hby4upY5hwcbigbAyL2hZoVqAkVERPqwvGoOlt7TYdLoZFcOqV7Ry1GJiIhIb8nXJPB6M2s2s81m9piZfawL+z5kZi1mttHM7jOzqZnsZGaVZjYlfAMmdC/8whDrF/hBbT01mxvaN8RGCG9ZA/WbEuwpIiIihS7fksA64OfAl4CjgAuB3YGnzey4NPuuBb4PnBfsexlwMPC8me2fwbkvwPc7DN8e6MZzKBjTw5NGh+cL1OAQERGRPi+v+gQ6514CXgqtetbMFgJLgR8Bj6XY91Hg0dCqRWb2cLDvVcDJaU4/D7g3bt0E+nAiOG23CooiRnOrY/HqWj45dbTfEE4Cq5fDuMNyE6CIiIj0mLxKAhNxztWa2UPAl82s1DmX8QzGzrmVZvY3IOX0MkHZGqAmvM7MuhxvISkdEGXS6HKWflDHi+F+gUN3hwFDYMdW1QSKiIj0UfnWHJxMLBtz3dy3NW2pfirWJLz0gzp2NAcvUyQClZP8co0Gh4iIiPRFeZ8Emtkw4ETgZedcQ7rycfvuARwOdHe6mT5vejA4ZEdzK8vX1LVvCI8Qdt3JvUVERCSf5VVzsJndBawG/g2sB/YGLgaqgDmhcvOBs4EJzrlVwbrHgUXAEmAzsB/wDXzt4WW99iQKTIdJo1fXtk0b05YENtbB5jUwdEwOohMREZGekm81gUuA44Cbgcfxo31XAIc55x4PlYsGt3CnvaXA6cBt+AEk3wCeBA5yzmV6tZF+Z7dhpYwqKwHi5gusCo8QVpOwiIhIX5NXNYHOuWuBazMoN4dQzWCw7qKeiapvMzOmj63gseXVyaeJqV4Oe3+894MTERGRHpNvNYGSA7Em4Q/rGviwLhh8PXgkDK70yxohLCIi0ucoCZS2K4cALF5V274h1iRcs7x3AxIREZEepyRQmDpmKMVR370yYZPwujegpTkHkYmIiEhPURIoDCyOMnnXoQAdJ42OJYEtjbDxnRxEJiIiIj1FSaAA7ZNGL19TR0NTi1/ZYYSwmoRFRET6EiWBArT3C2xqce2TRo+aSNssPBocIiIi0qcoCRQgbtLo2OCQAYNh2Hi/XK2aQBERkb5ESaAAsGtFKbuUDwSSDA5RTaCIiEifoiRQ2kwfVwH4wSEudr3gWL/Aje/Aju25CUxERESyTkmgtIk1CddsaeSD2mDS6LYrhzhY91puAhMREZGsUxIobaaHJ41eXesXwpePU5OwiIhIn6EkUNpM2bWcAVH/kVgcmy9wxASIDvDLNStyFJmIiIhkm5JAaVNSFGXqmHIgNDgkWgwj9/XLSgJFRET6DCWB0kGsX+CKNZvbJ42unOTvq5UEioiI9BVKAqWDWL/A5lbHkveDSaNjI4S3roXtG3MUmYiIiGSTkkDp4MAOg0OCJuEOg0NUGygiItIXKAmUDqrKBzKmohQIDQ4JJ4FqEhYREekTlARKJweMrQB8TaBzDobuBiV+wAg1unyciIhIX6AkUDqJDQ5Zv3UH722sB7P2wSGaK1BERKRPUBIonaTsF1jzKsQuKSciIiIFS0mgdDJpdDklRcGk0fFJYONmqHs/R5GJiIhItigJlE4GFEWYtttQIJQEVmmEsIiISF+iJFASivULfPXDLWzf0Rw3QliDQ0RERAqdkkBJ6IAgCWxpdbzyXh0MGg5DdvEbNThERESk4CkJlISmj6toW+7UJKzmYBERkYKnJFASqiwbyO7D/aTRL8UPDln/BrQ05SgyERERyQYlgZJUrF/g4tW1ftLoWBLYsgM2vJ3DyERERGRnKQmUpGJJ4MZtO1i5YXvcCGENDhERESlkeZUEmtksM3NJbodmsH+lmd1qZuvNbLuZPWdmx/RG7H1RLAmE4DrCI/cFzK/Q4BAREZGClldJYMi3gRlxt2WpdjCzEuAJ4BjgQuBkoBp41Mxm9mi0fdTE0WWUFkeBYHDIgEEwfE+/sVqDQ0RERApZUa4DSOJN59zzXdxnLjAVOMw59xyAmT0FvAL8CDgkuyH2fcVRP2n0C+9uZPHqWr+yajJsfFsjhEVERApcvtYEdscpwOuxBBDAOdcM3AF81MzG5CyyAjY9uI7w62s3s7UxNGn0ppWwY1vuAhMREZGdkq9J4PVm1mxmm83sMTP7WAb7TAWWJFgfWzcl1c5Bf8Ip4RswoYtx9zmxfoGtDl55rzZ05RAHNa/lLC4RERHZOfmWBNYBPwe+BByF79u3O/C0mR2XZt8RwMYE6zeGtqdyAb7fYfj2QGZh913Tx1a0LS9etanj5ePUJCwiIlKw8qpPoHPuJeCl0KpnzWwhsBTfr++xdIfo5jaAecC9cesm0M8TwRFDShg/YhArN2z3g0NmTYdoCbQ0KgkUEREpYPlWE9iJc64WeAiYZmalKYpuIHFt3/DgPlEtYfg8Nc655eEboBmRaW8Sfum9WlotCqP29RuqNVegiIhIocr7JDAQTE6XsjZvKbBfgvWxdSmnmJHkDggGh9Rub+Kd9dvam4Q1V6CIiEjByvsk0MyGAScCLzvnGlIUXQhMNLO2qWDMrAiYDbzgnFvTs5H2XR36Ba7e1H7lkG01sG19boISERGRnZJXSaCZ3WVm15rZacHVQ/4TeA6oAi4JlZsfjB4eF9p9AbAcuNfMzjSzY4HfA/sC3+zFp9Hn7FtVxuABftLol1ZrcIiIiEhfkFdJIH46l+OAm4HHge8DK/ATQD8eKhcNbrFmYpxzjfirhTwF/BJ4EBgNHO+ce6ZXou+jiqIR9t+9AoDFq2o7JoFrl+YkJhEREdk5eZUEOueudc4d4JyrcM4VOecqnXOfcc79K67cHOecOedWxq2vds6d7Zwb4Zwrdc7NiEsepZtig0PeqNnC5gGjYPAov+HZn0Ld+zmMTERERLojr5JAyV/Tx1UA4By8/F4dHHul37B9PfzuC9BUn7PYREREpOuUBEpGDth9WNvy4tWb4IDZcPB/+hUfvgwPXeQzRBERESkISgIlI8MGD2DPUYMBWLy61q/85P+DsYf55Vfuhhduyk1wIiIi0mV5dcUQyW/Txw7jnXXbeGn1JlpbHZFoMXzut/DrWbD5A3js2376mD2OzHWoIgXFOUdLq6O5NbhvcTS3ttLS6mhqdbQEj5uDbX59sL2ltW1fv60VM2NAUYSSaITioggDohEGFAW3aPt9bFtx1DCz9IGKSJ+iJFAyNn3sMP7w4vtsaWjmrXVb2aeqDIZUwul3wIJP+kvJ3TsHzn8aKsbmOlyRlFpaHVsamqirb2JzfTN19U1tt80NTWyub6KxOVGi1Z6M+aQtcXLWHErcOiV2sbKh4+Za5wTRgsfRYJ21bwsllSVFweNgXWxbSVHocaIkNG5bSVGEoqgRNSMS8ffR4HE0YkTMKIr4bSKSHUoCJWOxwSEAi1dt8kkgwJjpcNLP4P6vwPYNfqDIuY/BgEE5iVP6jx3NrWxuaOqYwAW3jus6J3lbGppzHX5e2dHcyo7mVmjMdSTpRSPtyaFPEIN1kQjRCG2JZCxpDJeNJZRtjxNug6JIJNiXtmMl2zcSxBAxX6MaW44YwePYcvoyfnuwLeLvIVY2XL69TNL925YTlzH8fUyHZTom2x23JV4fvzX5PnHHTnqe5DG0Oodz/r7V+dp0F6xvbfX3sXKtrr28S/W47bj+GB0eO0LnC/al/Vxtj0Mx4To+ds6x27BSPjl1dPyLljNKAiVje1eWUVZSxJbGZhav3sTnPxqq7fvImfDhK/DCjbB2CTx4IXzm14m+IUTaOOdoaGrtkJzVbW/qlLDVhRK7cEJX39TSY7FFI8bAoghF0UhbAlAcjRANEoKiqE86YssJy0QiRKPty0URX7tVHCQsRW3b4h53OGei80SSnjMaMZyDxuZWmlpa25K7ppZWdrS00hh+HFpujC/b7MvvaHbBfQtNLa6tzI6WjvexfXqjVrOl1dGCg557+0V6xMx9RikJlMIUjRgfGVvBs2+ubx8cEvaJa2DtMlj1N1j6e9j1IzDjv3o7TInjmxvbmx1bWkJ9z8LrkzRhJiwXawZtawJ1tLS0xm1vbz7d0tDcIaFrr7FrZkdLa48995KiCENLi9tu5XHL5QOLkm4fNCCqfnLd0NoaJI0JksrGuAQzvD6WQLa0+pqWltbQzTlag89Ta/C4pRVaWltpCWpiWuK2x8rHlsPHip2juSV0Lhc6XqhcSyimjufvuC1cKyWSTKyGMl8oCZQuOWDsMJ59cz1v1WylbnsTQwcVt28MDxSpew/+8l2omgJ7zspVuAXHOcfGbTtYU9vAB7X1fFBbz5rgtnZzAzua45Ox1rikrnPSlmffOV02pMQnamUpEjb/uCguwStmYHE01+H3O5GIMTAS7devvevQDNgxQUzUDNmpTKvr0PSYrLkzUZlEx4y/b4/DhWIOxd/p+YS3Jd4nfj8XvzHpPkliSHPscHO5mW84DjeXtzeJB03qcY+NULN6JO5xaP/4+7bj07HJPdwEHzFC5wv2wbAIFEfya1IWJYHSJdPHVrQtL35vE0ftW9mxwOCRwUCR46C5Ae49B85/CoaN79U489WO5lbW1nVO8MKPG5p6rmYsF4oixuCS+ASuqEMiVz6wY0IXrqkriubXl6ZIOma+L2EU1SRLflMSKF0SnjT6pVUJkkDwzcAn/QIWng/1G+F3s2HuX/r8QBHnHJvrmzsleO+Hlmu2NHa5Zq6kKMKYilJ2GTqQ0uKo7/sV6icW7qNWFOnYNyzcfyx+fVE0vmzocTTx+oTniCbYP3SvJlURkfykJFC6ZOigYvauHMKbNVsT9wuM2f90P1Dk+euhein86b/h1PkFPVCkuaWV6i2NfLCpc+3dmtp6PthUz7YdXe+pPmLwAHatKGVMRSm7VpSya8VAdhtW2rZu+OABSqRERCTrlARKl00fO4w3a7by8nu1tLQ6osnm7fr4VT4BfHcRLPsjjN4fDr+wd4Ptgq2NzSkTvLWbG7rc6bs4aj6xGxokdcNKGVMxMEj2fJLXn/tOiYhI7igJlC6bPq6Ce/79Hlsbm3mzZgsTdylPXDBaBKfdGgwUWY17/EpaR02hZc+j2zou+5F17VdMaI3r6NzamqBcqGN0rFxLa/tcTrHllnAn6db2bY3NLXxY19DeXBskfpu7MW/c0NLithq8MRUDGROqwRtTUcrIISWa3FZERPKSkkDpsulj2/sFfu7G5yiORjonbaHRavu4L/OH4ispZQdb7jyL/9hxDatdVQ6fQWaiEWOX8oE+oRvmm2ljNXi7VZQyuqKUISX6ExIRkcKkXzDpsgmjhjBySAnrtzZmVHu2nPF8s+l8fjHgV1TYNm4q/imf2fE96hnYC9EmN6SkKKjF61yDt2tFKVXlA5M3dYuIiBQ4JYHSZZGIccPs6dz/0ge0Otou2RSeEykSaV/2I0T35t8raznogzuYFHmPB3e/myemXEskuDRT+yWQgn1C8y+1HTtcLjSfkz9+ezmz9stGJSpXHI1QVT6QoaXF6Z+siIhIH6UkULrl4PHDOXj88K7t1PJzuPMDeOcp9lr3V/aKHgZHfK1nAhQREZGUNAur9J5oEZy2ACrG+cdPXAVvPp7bmERERPopJYHSuwYNh8/fBcWDAAd/PBc2vJ3rqERERPodJYHS+3aZCidf75cb6uB3X4DGLbmNSUREpJ9REii5MfUzcPj/+uV1r8L9X+l8xXARERHpMUoCJXeOuRwmHOOXX30Qnv1xbuMRERHpR5QESu5EonDafBi2h3/85PfhjcdyG5OIiEg/oSRQcqt0WDBQZDB+oMh5sP6tXEclIiLS5ykJlNyrmgyn3OCXGzfD786Ehs25jUlERKSPUxIo+WHyyXDE1/3y+tdh4ZehtTW3MYmIiPRheZ8Emtl5ZubMbGsGZecEZRPddumNeGUnHPVt2PsTfvn1h2HRdbmNR0REpA/L6yTQzMYAPwbWdHHXc4AZcbcN2Y1Osi4Shc/8BoZP8I+f/gG89khuYxIREemj8joJBG4EFgF/7eJ+y5xzz8fdmnogPsm20go/UGTAEP/4vvNh3Rs5DUlERKQvytsk0MxmAzOBC3Idi/Syyolwyk1+eceWYKBIXW5jEhER6WPyMgk0s0rgZ8Clzrn3u3GIh8ysxcw2mtl9ZjY1uxFKj5t0Isz8pl/e8KavEdRAERERkazJyyQQmAe8DtzQxf3WAt8HzgOOAi4DDgaeN7P9U+1oZpVmNiV8AyZ0PXTJmpmXwj7H++U3HoVnrs1tPCIiIn1IUa4DiGdmpwInAQc417WLyTrnHgUeDa1aZGYPA0uBq4CTU+x+AXBFF8OVnhSJwGdugt8c42sDn/kh7LIfTDop15GJiIgUvLyqCTSzIcD1wC+BNWZWYWYVwIBge4WZDe7KMZ1zK4G/AYemKToPmBp3S5U0Sm8YODQYKFLmHy/8MtS8ltuYRERE+oC8SgKBkUAVcDGwKXQ7AxgcLN/ZjeMakLJDmXOuxjm3PHwD3u7GuSTbRu0Dn/m1X96x1Q8Uqa/NaUgiIiKFLt+SwLX4vnzxt8eAhmD5u105oJntARwOPJ/VSKV3TTwBZn3bL298219juLUltzGJiIgUsLzqE+icawCejl9vZnOAFufc06F184GzgQnOuVXBusfx8wouATYD+wHfABx+kIgUsiMvgbVL4LWH4K2/wlPfh2Muz3VUIiIiBSnfagK7IhrcLLRuKXA6cBu+9vAbwJPAQc65Zb0eoWRXJAKfvgFG7usfP/sTWPFAbmMSEREpUAWRBDrn5jjnhiRYZ8HAj9i6i5xzU5xz5c65YufcGOfcF51zuuREXzGw3A8UKRnqHy/8ClSvyG1MIiIiBaggkkCRDkbuBaf+BjBo2hYMFNmU66hEREQKipJAKUz7HAdHf8cvb3oX/jBXA0VERES6QEmgFK4jvt4+cfTbT8ATV+U2HhERkQKiJFAKl5kfKDJqkn/895/BsvtyGpKIiEihUBIoha2kDD5/p7+yCMAD/wVrl+Y2JhERkQKgJFAK34gJcOoC/ECR7fC7L8D2jbmOSkREJK8pCZS+Ye9j2yeOrl0FfzgXWppzG5OIiEgeUxIofcfHLoLJn/bL7zwFT1yZy2hERETympJA6TvM4NPzoHKKf/yPX8LSP+Q2JhERkTylJFD6lgGDg4EiFf7xA/8NHy7JaUgiIiL5SEmg9D3D94DTFoBFoLneDxTZtiHXUYmIiOQVJYHSN+11DBx7pV+uWw1/mKOBIiIiIiFKAqXvOux/YOqpfvndRfDXy3Mbj4iISB5REih9lxn8x6+gaj//+Pnr4ZV7chuTiIhInlASKH3bgEF+oEjpcP/4wf+BNS/nNCQREZF8UJTrAER63LBx8Nlb4PZToLnBDxQ5+jswYAiUDIEBZcF96HFUfxoiItK36ZdO+oc9Z8EnroHHvg2b34f7v5K6fNHAFEniEH/N4vDjDtvi9hkwBCKqdBcRkfyiJFD6j0MvgNr34IUbAZe6bHODv21fn51zFw9OniQmSywTJZqRKGC+vyO037etS3efomzbdhER6Q+UBEr/YQbHXwuzvgn1m6BxK+zYGtxvSfN4KzRugR3bOq5Ll0zGNG3zN6p78hlmSQYJY9rkMvTYIn7y7sEjYfCo0H1oeVDsfniQ6IqISE9TEij9T+kwf9tZra3QtL0LiWSax831Ox9TVjhwrsPDnbZ9A2x8O4OCBoNGxCWLiZLH4HFJuWowRUS6SUmgSHdFIr6ptmQIlGXheC3NPiHsVPsYeuwcHZM0F7cu/j5Zmbj1kOY4qcqQukxrCzTUwrZ1sG29v9++AVxrghfB+Sb47ethXQavWaQ4ee1iouSxuDSDg4qI9A9KAkXyRbQISiv8ra9rbYH62iAxXNcxQYzdtm9oX26oS3KcJtiyxt8yMWCITwoHJatdHNG+PGgERIuz9pQlCeegpcm/ly1N0Nrsb23LLX5b27qdeRwcu1uPW0IxxY4bnMO1+m4MFgEL7iORjo8tEioT/zgaemxxj8PHsCT7pDpmijgiUYgO6HwrSrAuWgxFJe3L0WA5FnNf5xy07AhuTdDc2L7c0phifZN/3BwsDx0DEz+V62fTRkmgiPS+SDRIuEYAE9OXb97hawfbksQNSZLHYDlZ03qspnXTyszijP0ARor8D1+k2CfrkeLgh7C4fbnDtgEdy3XYP36/7mwrijtv3LYOidUOn8y07GhPtGI/TK3NoR+spiRl0uzTdo5MyiSIo7Up00+N5CWLSw67m1AWp9kntN6i7Z+p5lhiFndrDiVsXUnSkh0nW5/TvT6uJFBEpEuKBkD5rv6WiR3bEtcublsfWhdrml7vk5ZEYj8E0rdYtD3Jjt0SPo76xLptXWx7ccfHFvG1ga0t/j58a1sX3Le2xj0Ob3cJygfru7pPVjrzZsK1z6Yg6eXZ94mSQBHpewYM9rdh49OXbW0N+iyuj6ttXA9N9aFmxVBtVrjpskPtV6xcc+fark7b8uvHIK1ONY5BbWd0QMdtbTWnAzIsk6BGNRJO0rr6OFVSF0va+knzZbJENJaMttXYpqsZi6sl62otW9IauwT7JPuHrDuiodrGonBtY2i5KK4WMpPayqTHSlODGR3g56DNI0oCRaR/i0T81DSDhgP79N55YzU48Qll2mSzKcW2YNkiKZKvNMlYsjL9IXHqS2J9CwkS5ELR2pq+qbe1JX3ips9sRpQEiojkglmQqBVp1LJITCQCkRKfzJXkOpi+T9eyEhEREemH8j4JNLPzzMyZ2dYMy1ea2a1mtt7MtpvZc2Z2TE/HKSIiIlJI8joJNLMxwI+BjCYBM7MS4AngGOBC4GT8dboeNbOZPRWniIiISKHJ9z6BNwKLgI3AaRmUnwtMBQ5zzj0HYGZPAa8APwIO6aE4RURERApK3tYEmtlsYCZwQRd2OwV4PZYAAjjnmoE7gI8GNYsiIiIi/V5e1gSaWSXwM+BS59z7lvkw76nAswnWLwnupwAfpDjnqLjVEzI9sYiIiEghycskEJgHvA7c0MX9RuCbjuNtDG1P5gLgii6eT0RERKQg5V0SaGanAicBBzjnunPdm1T7pNo2D7g3bt0E4IFuxCAiIiKS1/IqCTSzIcD1wC+BNWZWEWwaEGyvAJqcc9uSHGIDiWv7hgf3iWoJAXDO1QA1cfFkGrqIiIhIQcm3gSEjgSrgYmBT6HYGMDhYvjPF/kuB/RKsj61blrVIRURERApYXtUEAmuBoxKsvxQ/Uvh4YH2K/RcC88zsEOfcCwBmVgTMBl5wzmU036CIiIhIX5dXSaBzrgF4On69mc0BWpxzT4fWzQfOBiY451YFqxcA/wXca2aX4pt3LwD2BY7tydhFRERECkm+NQd3RTS4tXXcc8414q8W8hS+X+GDwGjgeOfcM7kIUkRERCQf5VVNYDLOuTnAnHTrgvXV+BrCbBgA8NZbb2XpcCIiIiI9I5SvDMikvHVvFpb+wcz+A00RIyIiIoXlZOfcn9IVUhKYgpkNxQ9IeQ/Y0UOnic1FeDLwdg+doyco7t5XqLEr7t6luHuX4u5diju1AcDuwDPOubp0hQuiOThXghcwbSa9M0JzEb7tnFvek+fKJsXd+wo1dsXduxR371LcvUtxZ+SlTAsW8sAQEREREekmJYEiIiIi/ZCSQBEREZF+SElg7q0DvhfcFxLF3fsKNXbF3bsUd+9S3L1LcWeRRgeLiIiI9EOqCRQRERHph5QEioiIiPRDSgJFRERE+iElgSIiIiL9kJLAHDGzIWb2MzNbY2YNZvaymX0+13GlY2ZlZvYjM/uLma0zM2dmV+Y6rlTM7GgzW2Bmr5nZNjP7wMweMLMDcx1bOmb2ETN72MxWm1m9mW00s+fMbHauY+sKMzsv+KxszXUsqZjZrCDORLdDcx1fOmb2MTN7xMw2BZ+XN83sslzHlYyZ3Zri9c7r19zMDjCz+4Pv8O3B98vlZjYo17GlYmYfNbPHzGyLmW01s6fM7PBcxxXWld8ZM5tuZo8Hz6XWzO4zsz17OeRYLBnFHfyd3mxmL5pZY1BufO9HrCQwl+4DzsYPGT8e+Bdwt5mdmdOo0hsBnA+UAPfnNpSMfQUYD/wcOAG4EKgEnjezo3MYVyYq8Neu/jY+9rOAlcDtZvbd3IWVOTMbA/wYWJPrWLrg28CMuNuynEaURvDd8QxQh/+cnAD8ELBU++XY1XR+nWcA64EP8N+LecfMJgP/wH+v/C9wIvA74HLg7pwFloaZHQwsAkqBLwa3gcATZjYjl7HFyeh3xswmAk/jr5f7OeBcYB/gWTMb1eNRdpbp7+MxwLHAavznKHecc7r18g3/5eyAM+LW/wX/xRfNdYwpYjfapxYaGTyPK3MdV5qYKxOsGwKsBR7PdXzdfE7PA6tzHUeGsT6Ivwb3rcDWXMeTJtZZwWf6tFzH0sW4xwBbgXm5jiULz2Vm8B5cnetYUsR4TRDjhLj1NwXrh+U6xiRxPxp87w0KrSvDz13391zHF4opo98Z4PdB7OWhdeOAHcAP8zjuSGj560G58bl4rVUTmBun4L+w741bfwuwK3BIr0eUIRfIdRxd4ZyrSbBuK7AC2L33I8qK9UBzroNIJ2i2nglckOtY+rjzgMH4mr9CNxf/o7gg14Gk0BTc18WtrwVa8UlIPjoceNo5tz22wjm3BV87eJiZjc5ZZCGZ/M6YWRG+BvaPzrnNoX1XAU/hf2d7Vaa/j8651t6IJxNKAnNjKvCqcy7+R3xJaLv0IDMbCkwHluc6lkyYWcTMisxslJldABxHnv/gm1kl8DPgUufc+zkOp6uuN7NmM9sc9J/6WK4DSuNIYCMwMehf3GxmNWZ2o5mV5zq4TAV/l6cBTzjn3s11PCn8Fp/w3WBmewZ9wU4EvgRc75zbltPokhsANCZYH1u3Xy/GsrMm4Ju1lyTYtgTYy8wG9m5IhUdJYG6MwH9hx9sY2i4963p8zcn3cx1Ihubhax9qgP8D/sc5d1NuQ0prHvA6cEOuA+mCOnzf0S8BR+H7j+4OPG1mx+UysDTGAIPwrQv34PsbXYfvG/iImeVzv8CwM/A/7PNzHUgqzrmV+L6LU4G3gc34bg+/xX9m8tUK4FAza/vtD2rUYq1PhfTbE4s12W+pAcN6L5zCVJTrAPqxVFXGBdXcWmjM7GrgC8BXnXMv5jqeDP0AuBk/oOUk4FdmNtg59+PchpWYmZ2Kj/OAQuo+4Jx7CXgptOpZM1sILAV+BDyWk8DSi+A7+H/POXdtsO5pM9uBr409Bng8R7F1xVxgA7Aw14GkEozkfBCoxtdcrsMnUt/F9zeem7PgUvslPsH+lZl9H/+5uQLfjw58U3ah0W/pTlBNYG5sIPF/XMOD+0T/2UgWmNkV+C/q7zjnfpXreDLlnFvtnPu3c+4R59xXgF8D/y9HI+BSMrMh+JrWXwJrzKzCzCrwTVEEjwfnMMQucc7VAg8B08ysNMfhJLMhuI9PUv8c3E/vxVi6xcymAQcBdzjnEjVZ5pNrgXLgOOfcH51zi5xz1+FHCp9rZjNzGl0SzrkFwKX4UcHv40enTsaP3gc/MLFQxD7zyX5LHb7JXlJQEpgbS4FJQTV8WKw/Rl5PRVGoggTwSvxorR/kOJyd9U98TX5O5sNKYyRQBVwMbArdzsA3wW8C7sxZdN0Ta07N15qFRP2ioD3uQqjhidWe3ZzTKDLzEWBFgr5/sSlt8rZft3Puh/i/0f3wI1IPwzebbgMKpWUEfDN8PYn7Me4HvOWca+jdkAqPksDcWIhvMjg1bv3Z+LnUXuj1iPq4YMLcK4FrnHPfy3E42XAU/of9nVwHksBafHzxt8eAhmC5IOY4BDCzYfhRiC/n8Y/KH4P74+PWnxDcP9+LsXSZmZUAs4F/OucK4Z/gNcCUoNY7LDbXXl4PhHLONTrnljnnVpnZWOB04DfOufpcx5apYGDlg8BnzKwstj54Pkfh5+KVNNQnMAecc382s7/iR5aVA2/ha0k+Ccx2zrXkNMA0zOx4fI1O7A9vspmdFiw/Ep5+IB+Y2cXAVfg5sh6OvwqBcy5vfyDN7Nf4Tuf/xPc/Ggl8Fv+lfZ1zbl0Ow0soSJSejl9vZnOAFudcp235wszuwjeR/Rs/Dc/e+BrNKmBO7iJLzTn3FzN7ELg86PT/PL5p9QrgIefc33IaYHqfxjfhFUItIPh+lvcDfzWz/8N/Vg4FvoUffPHnpHvmkJlNxVc+/Bs/Inh/fPPwm0BeXVkmw9+ZK/C1rw+Z2bX4frFX4d+Pn/RyyEBmcQfdeGJdBmI1mceb2TpgnXPumV4LOBeTE+rWNlnxz4EP8X+MrwCfz3VcGca+Et8slug2PtfxJYj36RTxulzHlyb2c/BzeK3Djw7eFDyf2bmOrRvP5Vbyf7LoS/EDQ2rx8zDW4GsUDs51bBnEXorvq7Y6+Kyswg8oKsl1bBnE/hf83KlluY6lCzHHarc/BLbjR8L/GBiR69hSxLwP/qoyG4LfnTfxV20ZnOvYEsSa0e8McCB+0NM2/Oj+hcRN4p1vcdM+KX2i29O9GW9sZmsRERER6UfUJ1BERESkH1ISKCIiItIPKQkUERER6YeUBIqIiIj0Q0oCRURERPohJYEiIiIi/ZCSQBEREZF+SEmgiIiISD+kJFBERESkH1IS2AeY2Rwzc8FtVoLtZmZvBdufzvK5nZld2Y39xgf7zsmwfJWZXWtmS81sq5k1mNmbZvZzM9u7q+fvTWZ2pZn16KV5zGylmd0aerxrcN6P9ND5LjezFcF1alOV69L73B+Y2elmttzM6oPX5iO9eO4e/yz2pu5+/3Rl3505R5LjnZDseMG5fpXBMWLf+eOzFVdfZma3mtnKbu57u5ndn92I8kdRrgOQrNoCzMVfWzZsJjAh2F5wzOyjwEOAAb8CngN2APsCs4F/AsNyFmB+OAXYHHq8K/7i6iuBl7N5IjPbFfgGMMc515rNY/d1wYXjbwceBS7AX7/1jZwGVdhmAO8X2DlOAP4LuHInjvEwPq4PsxGQpHQl8JqZHe2cezLXwWSbksC+5R7gC2b2X865cEIwF584lecmrO4zs3LgAaABOMw5F/4yfhq4ycxOy0Vs+cQ591Ivnu5CoBa4rxfP2WVmVuqcq891HHH2AYqBO5xzz+Q6mELnnHu+L5yjq5xz64B1uY6jP3DOvW1mjwKXAn0uCVRzcN9yd3B/RmyFmQ0FTgUWJNrBzIab2Twz+8DMdpjZO2b2fTMriStXbma/MbMNQXPso2a2T5Jj7m1md5lZjZk1mtmrZvZf3XxO/wnsAnwjLgFs45z7Q9z5/8PMnjOz7Wa2xcz+amYz4spcGTSnTDOze82szsw2mtlPzazIzPYNnuOWoKn1G3H7zwr2nx3sszZo3nvGzA7I5IkFzYLPmdm24DV9LLyvmX3MzJrM7Mdx+8WaguaG1rU1B5vvEvCvYNMt1t5V4Eoz+2Kw3OH1CPa7PDjfriliHoD/p+Ku+FrAoAn698FrVmdm9+Dfu0THOcjM/hS85g1m9pKZfS5BuY8Fr1FD8Bm92szOi28KC57/Q2b2meBYDfiaUMxsFzO7yczeDz7j75rZFWZWFHeuAWb2XTN7LfjcrjOzW4Lau7TSfe6C9+dvwcN7LE33jND7/PEgjo3BZ+VBM9szQflzzeyV4LXaaGYLzWxSmpjnB2UHJdj2pJktDz12Zvar4DP0avA8XzGzExPs+zEzeyJ4Hbab2T/M7FNJnt/R1v7dstnMbjOzwcH79nszqzWzD83sx2ZWHHeMDk21ZjbK/PfZiuBvqiZ4Hkekeh3SvEbx54jFfZSZ3WBm64PY70v1txPseyu+FjB23NhtfFy5lK+xJWgONrMDgr+B2PfuGjN72Mx2y+A5Hhu8X5uDc/7dzI4Jbd872HZv3H5Hm1mLmV0dWne6mf0leM/qg+dxrZkNjn8tgvdoovnvvm3BPpcG2w81s78F698ws7OTvAYZ/X0keM5mZheY2ctBnJvM7A9J9r0dONbMJqQ7bsFxzulW4DdgDuCAg4DbgBdC274MbAXKgGXA06FtA4FXgu0XAx8HrgKagIdD5Qz/H1AD8O2g3JXA28F5rwyVnYyvJVoCfDEo+2OgBbgiVG58sO+cNM/tMaAZGJzha3FmcNzHgJOBzwH/xje7fSxU7sqg3GvAd4FjgR8G634JvAp8NVi/IFj/mdD+s4J1q4H7gROBLwBvAnXAnvHniovz20ArMB/4FL459x/BezE5VO6bwXn+I3g8BdgG3B53vJXArcFyeegzcTVwaHDbDRiAb0K6I27/IuAD4PdpXt8jguMeH7e+FFgRvPf/DXwC+DmwKv59Bo4K3o9FwftzHHBLgnLTgHr8Z/R04CR8M9i7Qdnxcc9/Df4zeU7w/hyMT0JXB9vPB44J3u8G4JbQ/hHgz8Hrf3nwvs/FNwMuB0p39nOH75JxQVDuW8F7MjnFMWPv4ergc/JJ/D9F1cG6ilDZbwVl78I3N34xeC1qgb2TfRaD19gB58Wde3Kw/oLQOhe89i8AnwWOB57Cf1+EP+8z8d01/h28DicHr0srcHqC5/cO/jvi4/huBs3B83gR+E7wXlwblP1aXJzx3z/7AvOCz8tM/N/Wzfjvn1mp9k3xPsSfIxb328Av8J/1ucBG4Mk0x5oA3Bvsf2joVtLF1zgWw/jg8WBgPf6fv88CRwav/Q3ApDQxzQ7em4X476ETgQeD9+GYULnTg3P+T/B4F2AtvkUmGir3XeB/8Z/DmcCXgvf4ybjz3or/+1gB/A8dv2t/ALwOnBu8vg8G6w/s5t/HrcDKuPP/Gv85/TH+O+gM/Pf+WqAqrmxlcK6vpvu8FNot5wHoloU3sWMSOCtYnhJs+yfBjx2dk8AvBWU/G3e8bwTrPx48/mT4jz9U7tt0/oJ8FHgPKI8r+0v8D/qw4PF4MksCXwU+zPB1iOATmSVAJLR+SPDF8PfQuitJ/KPyUrD+lNC6IqAG+GNoXex1fhGw0PpxwRfLb+LPFXq8O/5L/Rdx5x6CT9DuCa0zfOKzCZ8ALg9ek8Fx+64kSAKDxwcle32DeBqBytC6zwXlj0zzGsc+G/Ffkl8mlKyG1v86Po4g/sVAUVzZB/GJXCR4/Ht8UjYy7j1eTuIksBnYJ+6YN+L7wo6NW39xcIzJwePPE5fox72OX8nS5y72uTmtC3/X98WtPyxY/53gcQWwndA/bqHPWQNwZ7LPYrDuaeCluHXz8P/MDAmtc/gfyLLQuip8gnVpaN1zwfMO7xsFluK/Gyzu+cX/HSwM1l+U4G/zxbh1KRO54LxFwOMJXsedTQKvjyt3SbB+lzTH+1X8e9CN1zgWw/jg8YHB45PTPZ+48w0CNgB/SvCZfplQhULoc9GIT1yfCN7n0SmOb8Hrf2QQ37TQtlvp/M917LvWAQeE1g/H/33/pKt/H6FzrQw9PpTE3/+74f+WfpjgubwP/K4rr28h3NQc3Pc8g/8P9Vwz2w9fG5KwKRg4Gl+r9Ie49bcG97HmgKOC+zvjyt0VfmBmA4N9FgLbzTerFplvdnsEX/N4aJeeTdfsix8QcbsLNVU657YCfwQOTdDs9VDc41fxXw5/Du3fDLyFT/Di3eWCb4ig7Cp8jd5RCcrGHIf/srst7jVqwL9/s0LHc8BZ+ETm38AewOecc9tSHD+dG4L7/wyt+29gqXNuUZp9d8W/Puvj1h8FbHHO/SluffxnZC9gIsFnKcFnZDT+fQRfi/Ckc67tXMH7+vsksS1xzsUPsjgRX5OyJu5csfd3ZqhcLfBgXLmX8T/Ks5KcE7r3ueuKDn93zrl/4GtYY5+xGfia2Fvjyr2Hr8E/htR+DnzEzA6Htn64XwR+GzyHsKecc20DzJxz1fgf7XHBvoOBQ4A/hPd1zrXgm9R2o/39jUn0Nwj+n5/49Yn+Bjswsy+b2WLzXQKa8f9wHQOkbBrvhvjP+pLgPm2MaaR8jZN4C/+P4g+D5z85w3Mdhk+wfhv3uY/g/6E/OK4Z9yL8P2FP4f8mZjvnOgxOMbM9zXcHWotPXpvw32vQ+T1w+L/72HONfdd+6EL9nJ1zG0n+GqT7+0jkxODcd8Q977X4lodZCfapAcakOGZBUhLYxwRJwy34Kv4vA284555NUnwEsDacxATHqMF/eY4IlWt2zm2I239tguMV4ZtRm+JusT/0kV18SquBUfH9SZKIxZtoxNwa/Oc9fhTxxrjHO4DtzrmGBOsHJjhu/GsQWzciwfqYquD+X3R+nU4n7jUKXvc/Bed/1Dm3NMWx0wp+VO4BvmRmUTObhm/mTTs1BT7ZaAp+1MNG4GsF4sW/PrHn/mM6P/d5wbbY8092zETrIPH7XoVvRo4/V6yv28hQuQr8+xxfdhdSf26787nrinSfsXTnT/VZBD/waiVBXzV8Dctg4PoEZeO/A8DXDJUGy8PwtT/JYgnHG5PobzDZ+kR/g23M7Gv4f3JewPeFPhT/j/CjoRizJf61aAzud/Y86V7jTpxzdfh/aF7GN6UuD/oEfs/i+lHGif09/oHOn/tv4t/L4aHzNOL/sRsIvOyc+2v4YGY2BHgW/4/Ad2nvlvGZoEj8c0j2XRv/3sfWZ/M72PDfJfHP+1AS/703kP3PUM5pdHDfdCu+b9+X8X1qktkAHGJmFk4EzawS/9lYHypXZGYj4hLB+E7/m/D/+d1O4h8Q8P1duuIxfJ+Qk4DfpSkbi210gm274vu9bOri+dNJNPBhFxJ/kcfEXtfT8P+xpmRmHwe+gm/aP8XMTnXO/bGrgcb5Ob6252R8c38tnWt6E1kPDDCzwXG1kRuAjyYoH//6xJ77/yP56OLXQ8esSrA94WAT/H/28dbja2iS/R2sCZXbgH8tEkk1vVJPf+6SfcbeyvD88bW2HTjnWs3seuAHZnYxvt/iE86511Ptl8Qm/PNNFgvp4tlJs/FdXr4SXmlmZT14zrwQ/HP4eTMzfF/POfj+rfX4PpWJxN6LrwLJRkG3/dNlZlPxvy3/wtcSfs0599NQ2aPx7/MsFxr9bmYVXX0+XZDu7yOR9fjviyNoT97DEq0bjv9nqU9RTWAf5Jz7ALgO38fqtymKPoHvt/TpuPVnhbaDr/oHP/Ah7My4824Pyh6Ab5r7d4JbquQokfn4/+p+ZGYJq+LNLPZf5uv4vllnBl+Ese2D8bUCzwUxZtMZcecah29ieTrFPrHBLhOSvEb/Dh1vNHAHvjnlMHyN4Hwz2yNNXClrJZxzL+Kbrb+Jf19vzbCJ+bXgPn6U3FNAmZn9R9z6+M/I6/jBM/sne+6hprBngKPNrO2/cvOTU382gzhjHgKmAm8nOdeaULkR+A7uicqlSoh6+nPX4e/OzA7DN4s9Hax6Dv9DPzuu3G74H+UnSO9mfE3Lnfjm2kxqhTsJPkMvAJ8xs7bPXvC+zcb3q+rJeREdcT/gQU13p9HwOdQIfgqjnji4815xzl2E/+dueorifw/KTE7x97gjiHcwflDLSnxT66+Aa83skPDpg/v4JOpLO/u8Ukj395FIbN7ZMUmec4fWlqCpeHf8IJY+RTWBfZRz7tIMit2GbwL6rfmpBpYCH8MP+HjEOfd4UO4v+JGcPwq+CP4NHI6vSYp3IX4ajGfN7Ab8F0YZsBdwknPu6C4+jzozOxn/R/uS+dn0Y5NF743/Ydkf3zm41fxULncCD5nZTUAJvsN2BX6ep2yrBBaa2W+AocD38M0G/y/Fc1ppZpcD3w+mI3gUX4NSha9N2+acu8LMovhpfxxwpnOuxfyVN17GTzHysdgXdAJv4xODL5jZq/gBFmtCSQ/42sB7guPP63yIhJ4O7g+lvQ8U+M/SRfh+jt/BJ3on4Ps/xvsS8Gczewxfa/0B/r/sScB051wsyfs+vgb4CTP7fvB8voxvqgRf45TO5fhRp/8ws1/gE7aB+IFJJwBfdn7qod/hf0weMbOf42tdm/B92I4CHnDOLUx0gl743B1kZjfjf4B3x78uHxC8Z865WvNTdPzAzG7Df2ZG4KfIacB/JlMKjnEbvsZ5Ff4fyO76FvBX4Cnz0xvtwNcuTgXOiO9+kmUPAZeZ2ffw/0Tsi/8MvEv+/N7FEoxvmtmf8a0nS1L8LadlfgqZC/AzFbyDT3A+g//8/TXZfs65rWb2VfxvwHB8s3ANMAr/vToqVKt6IzAW+KhzbltQazwD+J2ZHeCcq8X/Y7kJuDF4D5rwf1f7d/e5ZSDl30cizrm/m9mv8VNoHYT/fduGr8H+GL5/9A2hXabhB9E81elghc7lwegU3XbuRmh0cJpyHUYHB+uG4/vQrMH/wa7E9ykpiSs3FF8rtwn/x/IX/BdspxF2+B/Y+fj/+nfgv1T+TsfRWuPJYHRwqHwVvkljWXD+BnyicSMwNa7syfimjXp88vM4fqLpcJkrg/OPjFt/K7A1wfmfBpaFHs8K9p+NT6ZqgpgWEZrGIHyuBMc8Gd9xvy7YdyX+i+yYYPs1+B+Io+P2mxG8Vz8LrVtJaHRwsO7z+M70O5K8TwOC8/65i5+3RcSNRA3Wj8H/iGzBX73kD0Gsnd5n/JfqPfimph34PmRPAF+KK/ex4L1sCMr8iPYRykPjnv9DSeIdGbxH7wTn2oD/R+YaQqOs8UnCxfgkuz54Hq8Gn7G9MnhdMvncxT43XRkd/HF8kr2JYBRwonjw05S8gq+FqcUnBJPjyiT8LAbbZgbn+2aS7Q74VYL1iT57Hwvez61BzM8BJyZ5fgclipEM/jbjP9fBZ/o6/HdPPX70/skkniKk099Eiud9ZQZxx97bWWmONwD4Df47o5WOo3wzeo3pPDp4X3xfvbeC17sWXyN7doZ/00fiE+gN+L+R94PHpwXbzyPx3/EE/PfXwtC6GfhkcFvwHH+Dbx3qsH+i9zNY/zSh79pkf+N04e8j0fsfrD8H/zcb+5y+hW89i/8Ovwo/OXdJ/DEK/RYbqi8iXWB+Quan8NPrxI+uLghmdhK+eflTzrlH0pUP7XcqPoEb53zXg15lZn/B//glnKy8rwhqfW8BDnahLgI9eL6f4GsCd3dd77Yh0qt66+8jaJF5Cz8TRKo+9gUpX6rHRaSXBNNHjAN+gq/1+nPKHTq7D98x/Fv4qWV6jJn9FD8/3Hv4Wusv4P/zn5tqP8mcmR2Kv5zdBcBNSgBFOpiN7zt/Xa4D6QlKAkX6n3n4Pp2L8c1FXWoOcM45M/tP4D/MLOLiLh+XZVF8U8wu+KafFcAXnXN39OA5+5vn8E1hD+Gn9RCRdhHgC873eexz1BwsIiIi0g9pihgRERGRfkhJoIiIiEg/pCRQREREpB9SEigiIiLSDykJFBEREemHlASKiIiI9ENKAkVERET6ISWBIiIiIv2QkkARERGRfkhJoIiIiEg/9P8BHkBr5MA7NA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_model_dataset(degree):\n",
    "    pipelined_model = Pipeline([\n",
    "            ('polynomial_transformation', PolynomialFeatures(degree)),\n",
    "            ('linear_regression', lm.LinearRegression())    \n",
    "        ])\n",
    "\n",
    "    pipelined_model.fit(X_train_mini[[\"hp\"]], Y_train_mini)\n",
    "    training_error = np.sqrt(mse(pipelined_model.predict(X_train_mini[[\"hp\"]]), Y_train_mini))\n",
    "    validation_error = np.sqrt(mse(pipelined_model.predict(X_val[[\"hp\"]]), Y_val))\n",
    "    return [degree, training_error, validation_error]\n",
    "    \n",
    "    \n",
    "    \n",
    "ks = np.array(range(0, 12))\n",
    "RMSEs = [fit_model_dataset(k) for k in ks]\n",
    "RMSEs_and_k = pd.DataFrame(RMSEs, columns = ['Degree', 'Training RMSE', 'Validation RMSE'])\n",
    "RMSEs_and_k\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "plt.plot(RMSEs_and_k[\"Degree\"], RMSEs_and_k[\"Validation RMSE\"], label=\"Val RMSE\")\n",
    "plt.plot(RMSEs_and_k[\"Degree\"], RMSEs_and_k[\"Training RMSE\"], label = \"Train RMSE\")\n",
    "plt.xlabel(\"Model Complexity (degree of polynomial in this example)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xticks(range(0, 12));\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b3792-f663-4fcf-b62e-de4d22a72898",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEs_and_k.rename(columns={\"k\":\"Degree\"}).set_index(\"Degree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3747069-c499-44b8-93a0-b30b1e6f0323",
   "metadata": {},
   "source": [
    "From this **model selection** process, we might choose to create a model with degree 2 (it gives the lowest validation RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e44e7-e3a9-46d0-af00-9424216738d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "It's possible that we may have, by random chance, selected a set of validation points that was *not* representative of other unseen data that the model might encounter (for example, if we happened to have selected all outlying data points for the validation set).\n",
    "\n",
    "\n",
    "Different train/validation splits lead to different validation errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c958576b-9488-4c7b-b741-38c3baa85e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val error from train/validation split #1: 4.983715333156557\n",
      "Val error from train/validation split #2: 4.928419779078926\n",
      "Val error from train/validation split #3: 5.166666016146992\n"
     ]
    }
   ],
   "source": [
    "# Examine different validation errors for the 2nd degree model:\n",
    "for i in range(1, 4):\n",
    "    X_train_mini, X_val, Y_train_mini, Y_val = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "    X_train_mini[\"hp^2\"] = X_train_mini[\"hp\"]\n",
    "    X_train_mini = X_train_mini[[\"hp\", \"hp^2\"]]\n",
    "    model = lm.LinearRegression()\n",
    "    model.fit(X_train_mini, Y_train_mini)\n",
    "    \n",
    "    X_val[\"hp^2\"] = X_val[\"hp\"]\n",
    "    X_val = X_val[[\"hp\", \"hp^2\"]] \n",
    "    y_hat = model.predict(X_val)\n",
    "    print(f\"Val error from train/validation split #{i}: {np.sqrt(mse(y_hat, Y_val))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7cc22",
   "metadata": {},
   "source": [
    "## A more complete process: K-Fold Cross-Validation\n",
    "\n",
    "The validation set gave us an opportunity to understand how the model performs on a **single** set of unseen data. The specific validation set we drew was fixed – we used the same vali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8725b-8863-4341-8641-0ae021f8ceba",
   "metadata": {},
   "source": [
    "To apply cross-validation, we use the `KFold` class of `sklearn.model_selection`. `KFold` will return the indices of each cross-validation fold. Then, we iterate over each of these folds to designate it as the validation set, while training the model on the remaining folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a66696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 5]\n",
      "[2 4 5 6 8]\n",
      "[0 1 2 3 4]\n",
      "[0 1 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(25) # Ensures reproducibility of this notebook\n",
    "\n",
    "\n",
    "# n_splits sets the number of folds to create\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X):\n",
    "    print(train_idx[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083123c0",
   "metadata": {},
   "source": [
    "## Let's do cross validation for each of the orders (up to order 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5e56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(25)\n",
    "\n",
    "def train_with_crossvalidation(degree, folds):\n",
    "    \n",
    "    # n_splits sets the number of folds to create\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    validation_errors = []\n",
    "\n",
    "    X = X_train[[\"hp\"]]\n",
    "    Y = Y_train\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('transform', PolynomialFeatures(degree = degree)),\n",
    "        ('regression', LinearRegression(fit_intercept = True))    \n",
    "    ])\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "      \n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        error = np.sqrt(mse(model.predict(split_X_valid), split_Y_valid))\n",
    "\n",
    "        validation_errors.append(error)\n",
    "    return np.mean(validation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440f03fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>folds</th>\n",
       "      <th>Ave RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.970268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.999445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.969897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.955661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.907638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.876761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.937045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.326312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.276685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.312839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.308889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.311993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.387003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.333445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4.265906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.334485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.327947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.381693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.334553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4.493205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.383068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.272185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.32683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4.434272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4.451457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.298455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4.348564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  folds  Ave RMSE\n",
       "0   0      2  8.002495\n",
       "1   0      3  7.970268\n",
       "2   0      4  7.999445\n",
       "3   0      5  7.969897\n",
       "4   1      2  4.955661\n",
       "5   1      3  4.907638\n",
       "6   1      4  4.876761\n",
       "7   1      5  4.937045\n",
       "8   2      2  4.326312\n",
       "9   2      3  4.276685\n",
       "10  2      4  4.312839\n",
       "11  2      5  4.308889\n",
       "12  3      2  4.311993\n",
       "13  3      3  4.387003\n",
       "14  3      4  4.333445\n",
       "15  3      5  4.265906\n",
       "16  4      2  4.334485\n",
       "17  4      3  4.327947\n",
       "18  4      4  4.381693\n",
       "19  4      5  4.334553\n",
       "20  5      2  4.493205\n",
       "21  5      3  4.383068\n",
       "22  5      4  4.272185\n",
       "23  5      5   4.32683\n",
       "24  6      2  4.434272\n",
       "25  6      3  4.451457\n",
       "26  6      4  4.298455\n",
       "27  6      5  4.348564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "ks = np.array(range(0, 7))\n",
    "folds = np.array(range(2, 6))\n",
    "RMSEs_CV = pd.DataFrame(columns = ['k', 'folds', 'Ave RMSE'])\n",
    "\n",
    "for k in ks:\n",
    "    for f in folds:\n",
    "        RMSEs_CV = RMSEs_CV.append({'k': k, 'folds': f, 'Ave RMSE': train_with_crossvalidation(k, f)}, \n",
    "                       ignore_index=True)\n",
    "\n",
    "RMSEs_CV['k'] = RMSEs_CV['k'].astype('int')\n",
    "RMSEs_CV['folds'] = RMSEs_CV['folds'].astype('int')\n",
    "\n",
    "RMSEs_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b05ad9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>folds</th>\n",
       "      <th>Ave RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.969897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.937045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.308889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4.265906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.334553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.32683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4.348564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  folds  Ave RMSE\n",
       "3   0      5  7.969897\n",
       "7   1      5  4.937045\n",
       "11  2      5  4.308889\n",
       "15  3      5  4.265906\n",
       "19  4      5  4.334553\n",
       "23  5      5   4.32683\n",
       "27  6      5  4.348564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSEs_CV[RMSEs_CV[\"folds\"]==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a577efc-ecd0-4757-854b-8d9c03e733f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ave RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.985526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.919276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.306181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.324587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.344669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.368822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.383187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ave RMSE\n",
       "k          \n",
       "0  7.985526\n",
       "1  4.919276\n",
       "2  4.306181\n",
       "3  4.324587\n",
       "4  4.344669\n",
       "5  4.368822\n",
       "6  4.383187"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking into RMSEs for different degree polynomials\n",
    "RMSEs_CV.groupby(\"k\")[\"Ave RMSE\"].mean().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6cf40",
   "metadata": {},
   "source": [
    "## Conclusion: This k-fold cross validation confirms that for this dataset, we would choose a _____  order model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef087bec",
   "metadata": {},
   "source": [
    "# After Model Selection, use training and validation sets to fit the final model: \n",
    " typically use the entire training set (both the \"mini\" training set and validation set) to fit the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cabd53fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we've used the validation set to determine the highest order of the polynomial, \n",
    "# we can create our FINAL model using all of the training data\n",
    "\n",
    "# This is where you apply your feature processing to get the final version of inputs for your model:\n",
    "\n",
    "# Create the input Design Matrix (here we're using polynomial of degree 2)\n",
    "X_use = X_train[[\"hp\"]]\n",
    "X_use[\"hp^2\"] = X_train[\"hp\"]**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_model = lm.LinearRegression()\n",
    "final_model.fit(X_use, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa39fe5-a467-44e5-8f2d-0948210c3a28",
   "metadata": {},
   "source": [
    "## Use the test data set (ONCE), to get your FINAL result\n",
    "After this choice has been finalized, and we are completely finished with the model design process, we finally assess model performance (ONCE) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8612574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of final model: 4.623522080196269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test[\"hp^2\"] = X_test[\"hp\"]**2\n",
    "X_test = X_test[[\"hp\", \"hp^2\"]]\n",
    "\n",
    "print(f\"Test RMSE of final model: {np.sqrt(mse(Y_test, final_model.predict(X_test)))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9504b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
